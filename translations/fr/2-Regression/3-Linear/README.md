# Construire un mod√®le de r√©gression avec Scikit-learn : quatre mani√®res de faire la r√©gression

## Note pour d√©butants

La r√©gression lin√©aire est utilis√©e lorsque nous voulons pr√©dire une **valeur num√©rique** (par exemple, le prix d'une maison, la temp√©rature ou les ventes).
Elle fonctionne en trouvant une ligne droite qui repr√©sente au mieux la relation entre les caract√©ristiques d'entr√©e et la sortie.

Dans cette le√ßon, nous nous concentrons sur la compr√©hension du concept avant d'explorer des techniques de r√©gression plus avanc√©es.
![Linear vs polynomial regression infographic](../../../../translated_images/fr/linear-polynomial.5523c7cb6576ccab.webp)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Quiz pr√©-conf√©rence](https://ff-quizzes.netlify.app/en/ml/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Introduction 

Jusqu'√† pr√©sent, vous avez explor√© ce qu'est la r√©gression avec des donn√©es d'exemple issues du jeu de donn√©es sur les prix des citrouilles que nous utiliserons tout au long de cette le√ßon. Vous l'avez aussi visualis√©e avec Matplotlib.

Vous √™tes maintenant pr√™t √† plonger plus profond√©ment dans la r√©gression pour le ML. Alors que la visualisation vous permet de comprendre les donn√©es, la v√©ritable puissance de l'apprentissage automatique vient de _l'entra√Ænement des mod√®les_. Les mod√®les sont entra√Æn√©s sur des donn√©es historiques pour capturer automatiquement les d√©pendances des donn√©es, et ils vous permettent de pr√©dire les r√©sultats pour de nouvelles donn√©es que le mod√®le n'a jamais vues auparavant.

Dans cette le√ßon, vous apprendrez davantage sur deux types de r√©gression : la _r√©gression lin√©aire basique_ et la _r√©gression polynomiale_, ainsi que sur une partie des math√©matiques sous-jacentes √† ces techniques. Ces mod√®les nous permettront de pr√©dire les prix des citrouilles en fonction de diff√©rentes donn√©es d'entr√©e. 

[![ML for beginners - Understanding Linear Regression](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML for beginners - Understanding Linear Regression")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la r√©gression lin√©aire.

> Tout au long de ce cursus, nous supposons des connaissances math√©matiques minimales, et cherchons √† les rendre accessibles aux √©tudiants venant d'autres domaines, donc faites attention aux notes, üßÆ encadr√©s, diagrammes et autres outils p√©dagogiques pour faciliter la compr√©hension.

### Pr√©requis

Vous devriez maintenant √™tre familier avec la structure des donn√©es sur les citrouilles que nous examinons. Vous pouvez les trouver pr√©charg√©es et pr√©-nettoy√©es dans le fichier _notebook.ipynb_ de cette le√ßon. Dans ce fichier, le prix des citrouilles est affich√© par boisseau dans un nouveau dataframe. Assurez-vous de pouvoir ex√©cuter ces notebooks dans les kernels de Visual Studio Code.

### Pr√©paration

Pour rappel, vous chargez ces donn√©es afin de pouvoir poser des questions √† leur sujet.

- Quel est le meilleur moment pour acheter des citrouilles ?
- Quel prix puis-je attendre pour un cas de mini-citrouilles ?
- Dois-je les acheter en paniers d‚Äôun demi-boisseau ou par bo√Æte de 1 1/9 boisseau ?
Continuons √† explorer ces donn√©es.

Dans la le√ßon pr√©c√©dente, vous avez cr√©√© un dataframe Pandas et l'avez rempli avec une partie du jeu de donn√©es initial, en standardisant les prix par boisseau. Cependant, cela ne vous a permis de rassembler qu'environ 400 points de donn√©es et uniquement pour les mois d'automne.

Jetez un ≈ìil aux donn√©es que nous avons pr√©charg√©es dans le notebook accompagnant cette le√ßon. Les donn√©es sont pr√©charg√©es et un premier nuage de points est trac√© pour montrer les donn√©es par mois. Peut-√™tre pouvons-nous en apprendre un peu plus sur la nature des donn√©es en les nettoyant davantage.

## Une ligne de r√©gression lin√©aire

Comme vous l'avez appris dans le√ßon 1, l'objectif d'un exercice de r√©gression lin√©aire est de pouvoir tracer une ligne pour :

- **Montrer les relations entre variables**. Montrer la relation entre les variables
- **Faire des pr√©dictions**. Faire des pr√©dictions pr√©cises sur la position d'un nouveau point de donn√©es par rapport √† cette ligne.

Il est typique de la **r√©gression des moindres carr√©s** de tracer ce type de ligne. Le terme "moindres carr√©s" fait r√©f√©rence au processus de minimisation de l'erreur totale dans notre mod√®le. Pour chaque point de donn√©es, nous mesurons la distance verticale (appel√©e r√©sidu) entre le point r√©el et notre ligne de r√©gression.

Nous √©levons au carr√© ces distances pour deux raisons principales :

1. **Importance plus que direction :** Nous voulons traiter une erreur de -5 de la m√™me fa√ßon qu'une erreur de +5. L'√©l√©vation au carr√© rend toutes les valeurs positives.

2. **P√©naliser les valeurs aberrantes :** L'√©l√©vation au carr√© donne plus de poids aux erreurs plus grandes, for√ßant la ligne √† rester plus proche des points √©loign√©s.

Nous additionnons ensuite toutes ces valeurs au carr√©. Notre objectif est de trouver la ligne sp√©cifique o√π cette somme finale est la plus petite possible ‚Äî d'o√π le nom "moindres carr√©s".

> **üßÆ Montrez-moi les math√©matiques**  
>  
> Cette ligne, appel√©e _ligne de meilleur ajustement_, peut √™tre exprim√©e par [une √©quation](https://en.wikipedia.org/wiki/Simple_linear_regression) :  
>  
> ```
> Y = a + bX
> ```
>
> `X` est la ¬´ variable explicative ¬ª. `Y` est la ¬´ variable d√©pendante ¬ª. La pente de la ligne est `b` et `a` est l'ordonn√©e √† l'origine, soit la valeur de `Y` lorsque `X = 0`.
>
>![calculate the slope](../../../../translated_images/fr/slope.f3c9d5910ddbfcf9.webp)
>
> Commencez par calculer la pente `b`. Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> En d'autres termes, et en se r√©f√©rant √† la question initiale de notre jeu de donn√©es sur la citrouille : ¬´ pr√©dire le prix d‚Äôune citrouille par boisseau selon le mois ¬ª, `X` ferait r√©f√©rence au prix et `Y` au mois de vente.
>
>![complete the equation](../../../../translated_images/fr/calculation.a209813050a1ddb1.webp)
>
> Calculez la valeur de Y. Si vous payez environ 4 $, cela doit √™tre en avril ! Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> La m√©thode math√©matique qui calcule la ligne doit d√©montrer la pente de la ligne, qui d√©pend aussi de l'ordonn√©e √† l'origine, ou de la position de `Y` lorsque `X = 0`.
>
> Vous pouvez observer la m√©thode de calcul de ces valeurs sur le site [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Visitez aussi [ce calculateur des moindres carr√©s](https://www.mathsisfun.com/data/least-squares-calculator.html) pour voir comment les valeurs des nombres impactent la ligne.

## Corr√©lation

Un terme suppl√©mentaire √† comprendre est le **coefficient de corr√©lation** entre les variables X et Y donn√©es. √Ä l‚Äôaide d‚Äôun nuage de points, vous pouvez rapidement visualiser ce coefficient. Un graphique avec des points de donn√©es align√©s proprement a une forte corr√©lation, tandis qu‚Äôun graphique avec des points dispers√©s partout entre X et Y a une faible corr√©lation.

Un bon mod√®le de r√©gression lin√©aire aura un coefficient de corr√©lation √©lev√© (plus proche de 1 que de 0) utilisant la m√©thode de r√©gression des moindres carr√©s avec une ligne de r√©gression.

‚úÖ Ex√©cutez le notebook accompagnant cette le√ßon et examinez le nuage Month vs Price. Les donn√©es associant le mois au prix des citrouilles semblent-elles offrir une corr√©lation √©lev√©e ou faible, selon votre interpr√©tation visuelle du scatterplot ? Est-ce que cela change si vous utilisez une mesure plus fine que `Month`, par ex. *jour de l'ann√©e* (nombre de jours depuis le d√©but de l'ann√©e) ?

Dans le code ci-dessous, nous supposerons que nous avons nettoy√© les donn√©es et obtenu un dataframe appel√© `new_pumpkins`, similaire au tableau suivant :

ID | Month | DayOfYear | Variety | City | Package | Low Price | High Price | Price
---|-------|-----------|---------|------|---------|-----------|------------|-------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 boisseau cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 boisseau cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 boisseau cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 boisseau cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 boisseau cartons | 15.0 | 15.0 | 13.636364

> Le code pour nettoyer les donn√©es est disponible dans [`notebook.ipynb`](notebook.ipynb). Nous avons effectu√© les m√™mes √©tapes de nettoyage que dans la le√ßon pr√©c√©dente, et avons calcul√© la colonne `DayOfYear` avec l'expression suivante : 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Maintenant que vous comprenez les math√©matiques derri√®re la r√©gression lin√©aire, cr√©ons un mod√®le de r√©gression pour voir si nous pouvons pr√©dire quel emballage de citrouilles aura les meilleurs prix. Quelqu‚Äôun achetant des citrouilles pour un patch de citrouilles de vacances pourrait vouloir cette information afin d‚Äôoptimiser ses achats.

## Recherche de Corr√©lation

[![ML for beginners - Looking for Correlation: The Key to Linear Regression](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML for beginners - Looking for Correlation: The Key to Linear Regression")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la corr√©lation.

D‚Äôapr√®s la le√ßon pr√©c√©dente, vous avez probablement vu que le prix moyen pour diff√©rents mois ressemble √† ceci :

<img alt="Average price by month" src="../../../../translated_images/fr/barchart.a833ea9194346d76.webp" width="50%"/>

Cela sugg√®re qu‚Äôil devrait y avoir une certaine corr√©lation, et nous pouvons essayer d‚Äôentra√Æner un mod√®le de r√©gression lin√©aire pour pr√©dire la relation entre `Month` et `Price`, ou entre `DayOfYear` et `Price`. Voici le graphique en nuage de points montrant cette derni√®re relation :

<img alt="Scatter plot of Price vs. Day of Year" src="../../../../translated_images/fr/scatter-dayofyear.bc171c189c9fd553.webp" width="50%" /> 

Voyons s‚Äôil y a une corr√©lation en utilisant la fonction `corr` :

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

Il semble que la corr√©lation soit assez faible, -0.15 pour `Month` et -0.17 pour `DayOfMonth`, mais il pourrait y avoir une autre relation importante. Il semble qu‚Äôil existe diff√©rents clusters de prix correspondant √† diff√©rentes vari√©t√©s de citrouilles. Pour confirmer cette hypoth√®se, tra√ßons chaque cat√©gorie de citrouille avec une couleur diff√©rente. En passant un param√®tre `ax` √† la fonction `scatter`, nous pouvons afficher tous les points sur le m√™me graphique :

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Scatter plot of Price vs. Day of Year" src="../../../../translated_images/fr/scatter-dayofyear-color.65790faefbb9d54f.webp" width="50%" /> 

Notre investigation sugg√®re que la vari√©t√© a plus d‚Äôeffet sur le prix global que la date de vente r√©elle. Nous pouvons en voir un graphique en barres :

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Bar graph of price vs variety" src="../../../../translated_images/fr/price-by-variety.744a2f9925d9bcb4.webp" width="50%" /> 

Concentrons-nous pour le moment sur une seule vari√©t√© de citrouille, le ¬´ type tarte ¬ª (pie type), et voyons quel effet la date a sur le prix :

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Scatter plot of Price vs. Day of Year" src="../../../../translated_images/fr/pie-pumpkins-scatter.d14f9804a53f927e.webp" width="50%" /> 

Si nous calculons maintenant la corr√©lation entre `Price` et `DayOfYear` avec la fonction `corr`, nous obtenons quelque chose comme `-0.27` ‚Äî ce qui signifie que l‚Äôentra√Ænement d‚Äôun mod√®le pr√©dictif a du sens.

> Avant d‚Äôentra√Æner un mod√®le de r√©gression lin√©aire, il est important de s‚Äôassurer que nos donn√©es sont propres. La r√©gression lin√©aire ne fonctionne pas bien avec des valeurs manquantes, il est donc judicieux d‚Äô√©liminer toutes les cellules vides :

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Une autre approche consisterait √† remplir ces valeurs vides avec la moyenne de la colonne correspondante.

## R√©gression Lin√©aire Simple

[![ML for beginners - Linear and Polynomial Regression using Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML for beginners - Linear and Polynomial Regression using Scikit-learn")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la r√©gression lin√©aire et polynomiale.

Pour entra√Æner notre mod√®le de r√©gression lin√©aire, nous allons utiliser la biblioth√®que **Scikit-learn**.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

Nous commen√ßons par s√©parer les valeurs d'entr√©e (features) et la sortie attendue (label) dans des tableaux numpy distincts :

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> Notez que nous avons d√ª effectuer un `reshape` sur les donn√©es d'entr√©e pour que le package de r√©gression lin√©aire les comprenne correctement. La r√©gression lin√©aire attend un tableau 2D en entr√©e, o√π chaque ligne du tableau correspond √† un vecteur de caract√©ristiques d'entr√©e. Dans notre cas, puisque nous n‚Äôavons qu‚Äôune seule entr√©e, nous avons besoin d‚Äôun tableau avec pour forme N&times;1, o√π N est la taille du jeu de donn√©es.

Ensuite, il faut diviser les donn√©es en ensembles d‚Äôentra√Ænement et de test, afin de pouvoir valider notre mod√®le apr√®s l'entra√Ænement :

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Enfin, l‚Äôentra√Ænement du mod√®le de r√©gression lin√©aire r√©el ne prend que deux lignes de code. Nous d√©finissons l‚Äôobjet `LinearRegression`, puis l‚Äôajustons √† nos donn√©es avec la m√©thode `fit` :

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

L‚Äôobjet `LinearRegression` apr√®s avoir √©t√© `fit` contient tous les coefficients de la r√©gression, auxquels on peut acc√©der via la propri√©t√© `.coef_`. Dans notre cas, il n‚Äôy a qu‚Äôun seul coefficient, qui devrait √™tre autour de `-0.017`. Cela signifie que les prix semblent diminuer un peu avec le temps, mais pas beaucoup, d‚Äôenviron 2 centimes par jour. On peut √©galement acc√©der au point d‚Äôintersection de la r√©gression avec l‚Äôaxe Y en utilisant `lin_reg.intercept_` ‚Äì il sera d‚Äôenviron `21` dans notre cas, indiquant le prix au d√©but de l‚Äôann√©e.

Pour voir √† quel point notre mod√®le est pr√©cis, nous pouvons pr√©dire les prix sur un ensemble de test, puis mesurer la proximit√© de nos pr√©dictions par rapport aux valeurs attendues. Cela peut √™tre fait √† l‚Äôaide de la m√©trique de l‚Äôerreur quadratique moyenne (MSE), qui est la moyenne de toutes les diff√©rences au carr√© entre la valeur attendue et la valeur pr√©dite.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```

Notre erreur semble √™tre d‚Äôenviron 2 points, soit ~17%. Pas tr√®s bon. Un autre indicateur de qualit√© du mod√®le est le **coefficient de d√©termination**, qui peut √™tre obtenu ainsi :

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```

Si la valeur est 0, cela signifie que le mod√®le ne prend pas en compte les donn√©es d‚Äôentr√©e et agit comme le *pire pr√©dicteur lin√©aire*, qui est simplement une valeur moyenne du r√©sultat. Une valeur de 1 signifie que nous pouvons pr√©dire parfaitement toutes les sorties attendues. Dans notre cas, le coefficient est autour de 0.06, ce qui est assez bas.

Nous pouvons aussi tracer les donn√©es de test avec la ligne de r√©gression pour mieux voir comment fonctionne la r√©gression dans notre cas :

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="Linear regression" src="../../../../translated_images/fr/linear-results.f7c3552c85b0ed1c.webp" width="50%" />

## R√©gression Polyn√¥miale

Un autre type de r√©gression lin√©aire est la r√©gression polynomiale. Parfois, il existe une relation lin√©aire entre les variables ‚Äî plus la citrouille est grosse en volume, plus le prix est √©lev√© ‚Äî mais parfois ces relations ne peuvent pas √™tre repr√©sent√©es par un plan ou une ligne droite.

‚úÖ Voici [quelques autres exemples](https://online.stat.psu.edu/stat501/lesson/9/9.8) de donn√©es pouvant √™tre analys√©es par r√©gression polynomiale.

Regardez de nouveau la relation entre Date et Prix. Ce nuage de points semble-t-il devoir n√©cessairement √™tre analys√© par une ligne droite ? Les prix ne peuvent-ils pas fluctuer ? Dans ce cas, vous pouvez essayer la r√©gression polynomiale.

‚úÖ Les polyn√¥mes sont des expressions math√©matiques qui peuvent contenir une ou plusieurs variables et coefficients.

La r√©gression polynomiale cr√©e une courbe pour mieux ajuster des donn√©es non lin√©aires. Dans notre cas, si nous incluons une variable au carr√© `DayOfYear` dans les donn√©es d'entr√©e, nous devrions pouvoir ajuster nos donn√©es avec une courbe parabolique, qui aura un minimum √† un certain moment de l‚Äôann√©e.

Scikit-learn inclut une API [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) utile pour combiner diff√©rentes √©tapes de traitement des donn√©es. Un **pipeline** est une cha√Æne d‚Äô**estimateurs**. Dans notre cas, nous allons cr√©er un pipeline qui d‚Äôabord ajoute des caract√©ristiques polynomiales √† notre mod√®le, puis entra√Æne la r√©gression :

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

Utiliser `PolynomialFeatures(2)` signifie que nous inclurons tous les polyn√¥mes du second degr√© issus des donn√©es d‚Äôentr√©e. Dans notre cas, cela signifie juste `DayOfYear`<sup>2</sup>, mais avec deux variables d‚Äôentr√©e X et Y, cela ajouterait X<sup>2</sup>, XY et Y<sup>2</sup>. On peut aussi utiliser des polyn√¥mes de degr√© sup√©rieur si on le souhaite.

Les pipelines peuvent √™tre utilis√©s comme l‚Äôobjet `LinearRegression` original, c‚Äôest-√†-dire qu‚Äôon peut les `fit`, puis utiliser `predict` pour obtenir les r√©sultats de la pr√©diction. Voici le graphique montrant les donn√©es de test et la courbe d‚Äôapproximation :

<img alt="Polynomial regression" src="../../../../translated_images/fr/poly-results.ee587348f0f1f60b.webp" width="50%" />

Avec la r√©gression polynomiale, on peut obtenir une MSE un peu plus faible et un coefficient de d√©termination plus √©lev√©, mais pas de mani√®re significative. Il faut prendre en compte d‚Äôautres caract√©ristiques !

> Vous voyez que les prix minimaux des citrouilles sont observ√©s quelque part autour d‚ÄôHalloween. Comment pouvez-vous l‚Äôexpliquer ?

üéÉ F√©licitations, vous venez de cr√©er un mod√®le qui peut aider √† pr√©dire le prix des citrouilles √† tarte. Vous pouvez probablement refaire la m√™me proc√©dure pour tous les types de citrouilles, mais ce serait fastidieux. Apprenons maintenant comment prendre en compte la vari√©t√© de citrouille dans notre mod√®le !

## Caract√©ristiques Cat√©gorielles

Dans un monde id√©al, nous voulons pouvoir pr√©dire les prix pour diff√©rentes vari√©t√©s de citrouilles avec le m√™me mod√®le. Cependant, la colonne `Variety` est quelque peu diff√©rente de colonnes comme `Month`, car elle contient des valeurs non num√©riques. Ces colonnes sont appel√©es **cat√©gorielles**.

[![ML for beginners - Categorical Feature Predictions with Linear Regression](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML for beginners - Categorical Feature Predictions with Linear Regression")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o pr√©sentant l‚Äôutilisation des caract√©ristiques cat√©gorielles.

Ici vous pouvez voir comment le prix moyen d√©pend de la vari√©t√© :

<img alt="Average price by variety" src="../../../../translated_images/fr/price-by-variety.744a2f9925d9bcb4.webp" width="50%" />

Pour prendre la vari√©t√© en compte, il faut d‚Äôabord la convertir en forme num√©rique, ou **l‚Äôencoder**. Plusieurs m√©thodes existent :

* L‚Äô**encodage num√©rique simple** cr√©e un tableau des diff√©rentes vari√©t√©s, puis remplace le nom de la vari√©t√© par un indice num√©rique dans ce tableau. Ce n‚Äôest pas la meilleure id√©e pour la r√©gression lin√©aire, car cette derni√®re prend la valeur num√©rique r√©elle de l‚Äôindice et la multiplie par un coefficient. Dans notre cas, la relation entre le num√©ro d‚Äôindice et le prix est clairement non lin√©aire, m√™me si on ordonne les indices d‚Äôune mani√®re sp√©cifique.
* L‚Äô**encodage one-hot** remplace la colonne `Variety` par 4 colonnes diff√©rentes, une pour chaque vari√©t√©. Chaque colonne contiendra `1` si la ligne correspond √† cette vari√©t√©, et `0` sinon. Cela signifie qu‚Äôil y aura quatre coefficients dans la r√©gression lin√©aire, un pour chaque vari√©t√© de citrouille, responsables du "prix de d√©part" (ou plut√¥t du "prix additionnel") pour cette vari√©t√© particuli√®re.

Le code ci-dessous montre comment faire un encodage one-hot d‚Äôune vari√©t√© :

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

Pour entra√Æner la r√©gression lin√©aire avec la vari√©t√© encod√©e en one-hot comme entr√©e, il suffit d‚Äôinitialiser correctement les donn√©es `X` et `y` :

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

Le reste du code est le m√™me que celui que nous avons utilis√© pr√©c√©demment pour entra√Æner la r√©gression lin√©aire. Si vous essayez, vous verrez que l‚Äôerreur quadratique moyenne reste √† peu pr√®s la m√™me, mais on obtient un coefficient de d√©termination beaucoup plus √©lev√© (~77%). Pour obtenir des pr√©dictions encore plus pr√©cises, on peut prendre en compte davantage de caract√©ristiques cat√©gorielles, ainsi que des caract√©ristiques num√©riques, comme `Month` ou `DayOfYear`. Pour avoir un grand tableau de caract√©ristiques combin√©es, on peut utiliser `join` :

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

Ici, nous prenons aussi en compte la `City` et le type `Package`, ce qui donne une MSE de 2.84 (10%) et un coefficient de d√©termination de 0.94 !

## Mettre tout ensemble

Pour faire le meilleur mod√®le, nous pouvons utiliser les donn√©es combin√©es (cat√©gorielles encod√©es one-hot + num√©riques) de l‚Äôexemple ci-dessus avec la r√©gression polynomiale. Voici le code complet pour votre commodit√© :

```python
# configurer les donn√©es d'entra√Ænement
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# faire la s√©paration train-test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# configurer et entra√Æner le pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# pr√©dire les r√©sultats pour les donn√©es de test
pred = pipeline.predict(X_test)

# calculer la MSE et le coefficient de d√©termination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Cela devrait nous donner le meilleur coefficient de d√©termination de presque 97%, et une MSE de 2.23 (~8% d‚Äôerreur de pr√©diction).

| Mod√®le | MSE | D√©termination |
|--------|-----|---------------|
| `DayOfYear` Lin√©aire | 2.77 (17.2%) | 0.07 |
| `DayOfYear` Polynomiale | 2.73 (17.0%) | 0.08 |
| `Variety` Lin√©aire | 5.24 (19.7%) | 0.77 |
| Toutes caract√©ristiques Lin√©aire | 2.84 (10.5%) | 0.94 |
| Toutes caract√©ristiques Polynomiale | 2.23 (8.25%) | 0.97 |

üèÜ Bravo ! Vous avez cr√©√© quatre mod√®les de r√©gression en une le√ßon, et am√©lior√© la qualit√© du mod√®le √† 97%. Dans la section finale sur la r√©gression, vous apprendrez la r√©gression logistique pour d√©terminer des cat√©gories.

---
## üöÄ D√©fi

Testez plusieurs variables diff√©rentes dans ce carnet pour voir comment la corr√©lation correspond √† la pr√©cision du mod√®le.

## [Quiz post-cours](https://ff-quizzes.netlify.app/en/ml/)

## R√©vision & Auto-apprentissage

Dans cette le√ßon, nous avons appris la r√©gression lin√©aire. Il existe d‚Äôautres types importants de r√©gression. Lisez sur les techniques Stepwise, Ridge, Lasso et Elasticnet. Un bon cours √† suivre pour en apprendre davantage est le [cours d‚Äôapprentissage statistique de Stanford](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning)

## Devoir

[Construisez un mod√®le](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avertissement** :
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des impr√©cisions. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou de mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->