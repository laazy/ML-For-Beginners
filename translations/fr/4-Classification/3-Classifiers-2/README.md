# Classificateurs de cuisine 2

Dans cette deuxi√®me le√ßon de classification, vous allez explorer davantage de fa√ßons de classer des donn√©es num√©riques. Vous apprendrez √©galement les cons√©quences du choix d‚Äôun classificateur plut√¥t qu‚Äôun autre.

## [Quiz pr√©-conf√©rence](https://ff-quizzes.netlify.app/en/ml/)

### Pr√©requis

Nous supposons que vous avez termin√© les le√ßons pr√©c√©dentes et que vous disposez d‚Äôun jeu de donn√©es nettoy√© dans votre dossier `data` appel√© _cleaned_cuisines.csv_ √† la racine de ce dossier de 4 le√ßons.

### Pr√©paration

Nous avons charg√© votre fichier _notebook.ipynb_ avec le jeu de donn√©es nettoy√© et l‚Äôavons divis√© en dataframes X et y, pr√™ts pour le processus de construction du mod√®le.

## Une carte de classification

Pr√©c√©demment, vous avez appris les diff√©rentes options dont vous disposez pour classifier des donn√©es en utilisant la fiche de r√©f√©rence de Microsoft. Scikit-learn offre une fiche de r√©f√©rence similaire, mais plus d√©taill√©e qui peut aider √† affiner encore plus vos estimateurs (un autre terme pour les classificateurs) :

![ML Map from Scikit-learn](../../../../translated_images/fr/map.e963a6a51349425a.webp)
> Astuce : [visitez cette carte en ligne](https://scikit-learn.org/stable/tutorial/machine_learning_map/) et cliquez le long du chemin pour lire la documentation.

### Le plan

Cette carte est tr√®s utile une fois que vous avez une compr√©hension claire de vos donn√©es, car vous pouvez ¬´¬†parcourir¬†¬ª ses chemins jusqu‚Äô√† une d√©cision :

- Nous avons >50 √©chantillons
- Nous voulons pr√©dire une cat√©gorie
- Nous avons des donn√©es √©tiquet√©es
- Nous avons moins de 100K √©chantillons
- ‚ú® Nous pouvons choisir un Linear SVC
- Si √ßa ne marche pas, comme nous avons des donn√©es num√©riques
    - Nous pouvons essayer un ‚ú® KNeighbors Classifier 
      - Si √ßa ne marche pas, essayer ‚ú® SVC et ‚ú® Ensemble Classifiers

C‚Äôest un chemin tr√®s utile √† suivre.

## Exercice - diviser les donn√©es

En suivant ce chemin, nous devrions commencer par importer quelques biblioth√®ques √† utiliser.

1. Importez les biblioth√®ques n√©cessaires :

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divisez vos donn√©es d‚Äôentra√Ænement et de test :

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Classificateur Linear SVC

Le support-vector clustering (SVC) appartient √† la famille des machines √† vecteurs de support (Support-Vector machines) en apprentissage automatique (apprenez-en plus ci-dessous). Dans cette m√©thode, vous pouvez choisir un 'kernel' pour d√©cider comment regrouper les √©tiquettes. Le param√®tre 'C' fait r√©f√©rence √† la ¬´ r√©gularisation ¬ª qui r√©gule l‚Äôinfluence des param√®tres. Le kernel peut √™tre un des [plusieurs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) ; ici nous l‚Äôavons fix√© √† 'linear' pour garantir l‚Äôutilisation du Linear SVC. La probabilit√© est par d√©faut √† 'false' ; ici nous la mettons √† 'true' pour recueillir des estimations de probabilit√©. Nous fixons l‚Äô√©tat al√©atoire √† '0' pour m√©langer les donn√©es et obtenir des probabilit√©s.

### Exercice - appliquer un Linear SVC

Commencez par cr√©er un tableau de classificateurs. Vous ajouterez progressivement √† ce tableau au fur et √† mesure de nos tests.

1. Commencez par un Linear SVC :

    ```python
    C = 10
    # Cr√©er diff√©rents classificateurs.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Entra√Ænez votre mod√®le en utilisant le Linear SVC et affichez un rapport :

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Le r√©sultat est assez bon :

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificateur K-Neighbors

K-Neighbors fait partie de la famille des m√©thodes ML ¬´ voisins ¬ª ("neighbors"), qui peuvent √™tre utilis√©es pour l‚Äôapprentissage supervis√© et non supervis√©. Dans cette m√©thode, un nombre pr√©d√©fini de points est cr√©√© et les donn√©es sont regroup√©es autour de ces points de mani√®re √† pr√©dire des √©tiquettes g√©n√©ralis√©es pour les donn√©es.

### Exercice - appliquer le classificateur K-Neighbors

Le classificateur pr√©c√©dent √©tait bon, et a bien fonctionn√© avec les donn√©es, mais peut-√™tre pouvons-nous obtenir une meilleure pr√©cision. Essayez un classificateur K-Neighbors.

1. Ajoutez une ligne √† votre tableau de classificateurs (ajoutez une virgule apr√®s l‚Äô√©l√©ment Linear SVC) :

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Le r√©sultat est un peu moins bon :

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ D√©couvrez [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificateur Support Vector

Les classificateurs Support-Vector font partie de la famille des [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) en apprentissage automatique, utilis√©s pour les t√¢ches de classification et de r√©gression. Les SVM ¬´ projettent les exemples d‚Äôapprentissage en points dans un espace ¬ª pour maximiser la distance entre deux cat√©gories. Les donn√©es suivantes sont projet√©es dans cet espace afin que leur cat√©gorie puisse √™tre pr√©dite.

### Exercice - appliquer un classificateur Support Vector

Essayons d‚Äôobtenir une pr√©cision un peu meilleure avec un classificateur Support Vector.

1. Ajoutez une virgule apr√®s l‚Äô√©l√©ment K-Neighbors, puis ajoutez cette ligne :

    ```python
    'SVC': SVC(),
    ```

    Le r√©sultat est assez bon !

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ D√©couvrez les [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificateurs en ensemble

Suivons le chemin jusqu‚Äôau bout, m√™me si le test pr√©c√©dent √©tait assez bon. Essayons des ¬´ ensemble classifiers ¬ª, sp√©cifiquement Random Forest et AdaBoost :

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Le r√©sultat est tr√®s bon, surtout pour Random Forest :

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ D√©couvrez les [classificateurs en ensemble](https://scikit-learn.org/stable/modules/ensemble.html)

Cette m√©thode de Machine Learning ¬´ combine les pr√©dictions de plusieurs estimateurs de base ¬ª pour am√©liorer la qualit√© du mod√®le. Dans notre exemple, nous avons utilis√© Random Trees et AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), une m√©thode de moyennage, construit une ¬´ for√™t ¬ª d‚Äô¬´ arbres de d√©cision ¬ª infusionn√©s de hasard pour √©viter le surapprentissage. Le param√®tre n_estimators est fix√© au nombre d‚Äôarbres.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajuste un classificateur √† un jeu de donn√©es, puis ajuste des copies de ce classificateur au m√™me jeu de donn√©es. Il se concentre sur les poids des √©l√©ments mal classifi√©s et ajuste l‚Äôajustement pour le classificateur suivant afin de corriger.

---

## üöÄD√©fi

Chacune de ces techniques poss√®de un grand nombre de param√®tres que vous pouvez modifier. Recherchez les param√®tres par d√©faut de chacune et r√©fl√©chissez √† ce que modifier ces param√®tres signifierait pour la qualit√© du mod√®le.

## [Quiz post-conf√©rence](https://ff-quizzes.netlify.app/en/ml/)

## Revue & Auto-apprentissage

Il y a beaucoup de jargon dans ces le√ßons, alors prenez un instant pour revoir [cette liste](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminologie utile !

## Devoir 

[Jeu avec les param√®tres](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous effor√ßons d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source autoritaire. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou erreurs d‚Äôinterpr√©tation r√©sultant de l‚Äôutilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->