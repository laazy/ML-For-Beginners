# ClassifikÃ¡tory kuchynÃ­ 2

V tÃ©to druhÃ© lekci klasifikace prozkoumÃ¡te vÃ­ce zpÅ¯sobÅ¯, jak klasifikovat ÄÃ­selnÃ¡ data. TakÃ© se dozvÃ­te o dÅ¯sledcÃ­ch vÃ½bÄ›ru jednoho klasifikÃ¡toru pÅ™ed druhÃ½m.

## [PÅ™ednÃ¡Å¡kovÃ½ kvÃ­z](https://ff-quizzes.netlify.app/en/ml/)

### PÅ™edpoklady

PÅ™edpoklÃ¡dÃ¡me, Å¾e jste dokonÄili pÅ™edchozÃ­ lekce a mÃ¡te vyÄiÅ¡tÄ›nÃ½ dataset ve sloÅ¾ce `data` pojmenovanÃ½ _cleaned_cuisines.csv_ v koÅ™enovÃ© sloÅ¾ce tÃ©to sady ÄtyÅ™ lekcÃ­.

### PÅ™Ã­prava

Do vaÅ¡eho souboru _notebook.ipynb_ jsme vloÅ¾ili vyÄiÅ¡tÄ›nÃ½ dataset a rozdÄ›lili jej na datovÃ© rÃ¡mce X a y, pÅ™ipravenÃ© pro tvorbu modelu.

## Mapa klasifikace

DÅ™Ã­ve jste se seznÃ¡mili s rÅ¯znÃ½mi moÅ¾nostmi pÅ™i klasifikaci dat podle Microsoftova pÅ™ehledu. Scikit-learn nabÃ­zÃ­ podobnÃ½, ale detailnÄ›jÅ¡Ã­ pÅ™ehled, kterÃ½ vÃ¡m mÅ¯Å¾e dÃ¡le pomoci zÃºÅ¾it vÃ½bÄ›r odhadovaÄÅ¯ (jinÃ½ termÃ­n pro klasifikÃ¡tory):

![ML Map from Scikit-learn](../../../../translated_images/cs/map.e963a6a51349425a.webp)
> Tip: [navÅ¡tivte tuto mapu online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) a klikÃ¡nÃ­m postupujte po cestÄ› k dokumentaci.

### PlÃ¡n

Tato mapa je velmi uÅ¾iteÄnÃ¡, pokud mÃ¡te jasnÃ½ pÅ™ehled o svÃ½ch datech, protoÅ¾e mÅ¯Å¾ete â€jÃ­tâ€œ po jejÃ­ch cestÃ¡ch k rozhodnutÃ­:

- MÃ¡me vÃ­ce neÅ¾ 50 vzorkÅ¯
- Chceme pÅ™edpovÄ›dÄ›t kategorii
- MÃ¡me oznaÄenÃ¡ data
- MÃ¡me mÃ©nÄ› neÅ¾ 100 tisÃ­c vzorkÅ¯
- âœ¨ MÅ¯Å¾eme zvolit Linear SVC
- Pokud to nefunguje, protoÅ¾e mÃ¡me ÄÃ­selnÃ¡ data
    - MÅ¯Å¾eme zkusit âœ¨ KNeighbors Classifier
      - Pokud to nepomÅ¯Å¾e, zkusit âœ¨ SVC a âœ¨ Ensemble Classifiers

Toto je velmi uÅ¾iteÄnÃ¡ cesta, kterou lze nÃ¡sledovat.

## CviÄenÃ­ â€“ rozdÄ›lenÃ­ dat

Podle tÃ©to cesty bychom mÄ›li zaÄÃ­t importem nÄ›kterÃ½ch knihoven, kterÃ© pouÅ¾ijeme.

1. Naimportujte potÅ™ebnÃ© knihovny:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. RozdÄ›lte vaÅ¡e trÃ©novacÃ­ a testovacÃ­ data:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## KlasifikÃ¡tor Linear SVC

Support-Vector clustering (SVC) je metodou z rodiny Support-Vector machine ML technik (o tÄ›chto se dozvÃ­te dÃ¡le). V tÃ©to metodÄ› mÅ¯Å¾ete zvolit â€kernelâ€œ, kterÃ½ rozhoduje, jak seskupit Å¡tÃ­tky. Parametr â€Câ€œ odkazuje na â€regularizaciâ€œ, kterÃ¡ reguluje vliv parametrÅ¯. Kernel mÅ¯Å¾e bÃ½t jeden z [nÄ›kolika](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); zde jej nastavujeme na â€šlinearâ€˜, abychom vyuÅ¾ili lineÃ¡rnÃ­ SVC. PravdÄ›podobnost (probability) je standardnÄ› â€falseâ€œ; zde nastavujeme na â€trueâ€œ, aby bylo moÅ¾nÃ© zÃ­skat odhady pravdÄ›podobnostÃ­. NÃ¡hodnÃ½ stav je nastaven na â€0â€œ pro promÃ­chÃ¡nÃ­ dat a zÃ­skÃ¡nÃ­ pravdÄ›podobnostÃ­.

### CviÄenÃ­ â€“ aplikujte lineÃ¡rnÃ­ SVC

ZaÄnÄ›te vytvoÅ™enÃ­m pole klasifikÃ¡torÅ¯. PostupnÄ› do nÄ›j budete pÅ™idÃ¡vat dalÅ¡Ã­ pÅ™i testovÃ¡nÃ­.

1. ZaÄnÄ›te s Linear SVC:

    ```python
    C = 10
    # VytvoÅ™te rÅ¯znÃ© klasifikÃ¡tory.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. NatrÃ©nujte svÅ¯j model pomocÃ­ Linear SVC a zobrazte report:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    VÃ½sledek je pomÄ›rnÄ› dobrÃ½:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## KlasifikÃ¡tor K-Neighbors

K-Neighbors je souÄÃ¡stÃ­ rodiny ML metod â€neighborsâ€œ, kterÃ© lze pouÅ¾Ã­t pro jak uÄenÃ­ s uÄitelem, tak bez uÄitele. V tÃ©to metodÄ› je vytvoÅ™en pÅ™edem definovanÃ½ poÄet bodÅ¯ a data jsou shromaÅ¾ÄovÃ¡na kolem tÄ›chto bodÅ¯, aby bylo moÅ¾nÃ© pro data pÅ™edpovÃ­dat obecnÃ© Å¡tÃ­tky.

### CviÄenÃ­ â€“ aplikujte klasifikÃ¡tor K-Neighbors

PÅ™edchozÃ­ klasifikÃ¡tor byl dobrÃ½ a dobÅ™e fungoval s daty, ale moÅ¾nÃ¡ mÅ¯Å¾eme dosÃ¡hnout lepÅ¡Ã­ pÅ™esnosti. VyzkouÅ¡ejte klasifikÃ¡tor K-Neighbors.

1. PÅ™idejte Å™Ã¡dek do pole klasifikÃ¡torÅ¯ (pÅ™idejte ÄÃ¡rku za poloÅ¾ku Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    VÃ½sledek je trochu horÅ¡Ã­:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… NauÄte se o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector Classifier

Support-Vector klasifikÃ¡tory jsou souÄÃ¡stÃ­ rodiny [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) ML metod, kterÃ© se pouÅ¾Ã­vajÃ­ pro klasifikaci a regresnÃ­ Ãºlohy. SVM mapujÃ­ trÃ©ninkovÃ© pÅ™Ã­klady do bodÅ¯ ve vesmÃ­ru za ÃºÄelem maximalizace vzdÃ¡lenosti mezi dvÄ›ma kategoriemi. NÃ¡slednÃ¡ data jsou pak do tohoto prostoru namapovÃ¡na tak, aby bylo moÅ¾nÃ© pÅ™edpovÄ›dÄ›t jejich kategorii.

### CviÄenÃ­ â€“ aplikujte Support Vector Classifier

Zkuste dosÃ¡hnout trochu lepÅ¡Ã­ pÅ™esnosti pomocÃ­ Support Vector Classifier.

1. PÅ™idejte ÄÃ¡rku za poloÅ¾ku K-Neighbors a potom pÅ™idejte tento Å™Ã¡dek:

    ```python
    'SVC': SVC(),
    ```

    VÃ½sledek je docela dobrÃ½!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… NauÄte se o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble Classifiers

PojÄme jÃ­t cestou aÅ¾ do konce, i kdyÅ¾ pÅ™edchozÃ­ test byl pomÄ›rnÄ› dobrÃ½. VyzkouÅ¡ejme nÄ›kterÃ© 'Ensemble Classifiers', konkrÃ©tnÄ› Random Forest a AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

VÃ½sledek je velmi dobrÃ½, zvlÃ¡Å¡tÄ› u Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… NauÄte se o [Ensemble Classifiers](https://scikit-learn.org/stable/modules/ensemble.html)

Tato metoda strojovÃ©ho uÄenÃ­ â€kombinuje pÅ™edpovÄ›di nÄ›kolika zÃ¡kladnÃ­ch odhadovaÄÅ¯â€œ ke zlepÅ¡enÃ­ kvality modelu. V naÅ¡em pÅ™Ã­kladu jsme pouÅ¾ili Random Trees a AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), metoda prÅ¯mÄ›rovÃ¡nÃ­, vytvÃ¡Å™Ã­ â€lesâ€œ rozhodovacÃ­ch stromÅ¯ obohacenÃ½ch nÃ¡hodnostÃ­, aby se pÅ™edeÅ¡lo pÅ™etrÃ©novÃ¡nÃ­. Parametr n_estimators je nastaven na poÄet stromÅ¯.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) uÄÃ­ klasifikÃ¡tor na datovÃ© sadÄ› a potom uÄÃ­ jeho kopie na tÃ©Å¾e datovÃ© sadÄ›. ZamÄ›Å™uje se na vÃ¡hy nesprÃ¡vnÄ› klasifikovanÃ½ch poloÅ¾ek a upravuje pÅ™izpÅ¯sobenÃ­ pro dalÅ¡Ã­ klasifikÃ¡tor, aby chyby korigoval.

---

## ğŸš€ VÃ½zva

KaÅ¾dÃ¡ z tÄ›chto technik mÃ¡ mnoho parametrÅ¯, kterÃ© mÅ¯Å¾ete ladit. Prozkoumejte vÃ½chozÃ­ parametry kaÅ¾dÃ© a zamyslete se, co by zmÄ›na tÄ›chto parametrÅ¯ znamenala pro kvalitu modelu.

## [Po pÅ™ednÃ¡Å¡kovÃ½ kvÃ­z](https://ff-quizzes.netlify.app/en/ml/)

## PÅ™ehled a samostudium

V tÄ›chto lekcÃ­ch je hodnÄ› odbornÃ½ch vÃ½razÅ¯, takÅ¾e si udÄ›lejte chvÃ­li na zopakovÃ¡nÃ­ [tohoto seznamu](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) uÅ¾iteÄnÃ© terminologie!

## ZadÃ¡nÃ­

[Hra s parametry](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**UpozornÄ›nÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by automatickÃ©ho pÅ™ekladu [Co-op Translator](https://github.com/Azure/co-op-translator). PÅ™estoÅ¾e usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. OriginÃ¡lnÃ­ dokument v pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za zÃ¡vaznÃ½ zdroj. Pro zÃ¡sadnÃ­ informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dni za jakÃ©koliv nedorozumÄ›nÃ­ nebo mylnÃ© vÃ½klady vzniklÃ© pouÅ¾Ã­vÃ¡nÃ­m tohoto pÅ™ekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->