# Classificadores de culin√°ria 2

Nesta segunda aula de classifica√ß√£o, voc√™ explorar√° mais maneiras de classificar dados num√©ricos. Voc√™ tamb√©m aprender√° sobre as ramifica√ß√µes de escolher um classificador em vez de outro.

## [Quiz pr√©-lectura](https://ff-quizzes.netlify.app/en/ml/)

### Pr√©-requisito

Pressupomos que voc√™ tenha conclu√≠do as li√ß√µes anteriores e possua um conjunto de dados limpo na sua pasta `data` chamado _cleaned_cuisines.csv_ na raiz desta pasta de 4 aulas.

### Prepara√ß√£o

Carregamos seu arquivo _notebook.ipynb_ com o conjunto de dados limpo e o dividimos em dataframes X e y, prontos para o processo de constru√ß√£o do modelo.

## Um mapa de classifica√ß√£o

Anteriormente, voc√™ aprendeu sobre as v√°rias op√ß√µes que existem ao classificar dados usando a folha de dicas da Microsoft. O Scikit-learn oferece uma folha de dicas semelhante, mas mais granular, que pode ajudar ainda mais a afunilar seus estimadores (outro termo para classificadores):

![ML Map from Scikit-learn](../../../../translated_images/pt-BR/map.e963a6a51349425a.webp)
> Dica: [visite este mapa online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) e clique ao longo do caminho para ler a documenta√ß√£o.

### O plano

Este mapa √© muito √∫til assim que voc√™ tiver uma compreens√£o clara dos seus dados, pois pode ‚Äúpercorrer‚Äù seus caminhos at√© uma decis√£o:

- Temos >50 amostras
- Queremos prever uma categoria
- Temos dados rotulados
- Temos menos de 100K amostras
- ‚ú® Podemos escolher um Linear SVC
- Se isso n√£o funcionar, j√° que temos dados num√©ricos
    - Podemos tentar um classificador ‚ú® KNeighbors 
      - Se isso n√£o funcionar, tente ‚ú® SVC e ‚ú® Classificadores Ensemble

Este √© um caminho muito √∫til para seguir.

## Exerc√≠cio - divida os dados

Seguindo este caminho, devemos come√ßar importando algumas bibliotecas para usar.

1. Importe as bibliotecas necess√°rias:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divida seus dados de treino e teste:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Classificador Linear SVC

Support-Vector clustering (SVC) √© um membro da fam√≠lia de m√°quinas de suporte vetorial (Support-Vector machines) de t√©cnicas de ML (saiba mais sobre elas abaixo). Neste m√©todo, voc√™ pode escolher um 'kernel' para decidir como agrupar as etiquetas. O par√¢metro 'C' refere-se √† 'regulariza√ß√£o', que regula a influ√™ncia dos par√¢metros. O kernel pode ser um de [v√°rios](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); aqui definimos como 'linear' para garantir que aproveitamos o linear SVC. A probabilidade tem padr√£o 'false'; aqui definimos como 'true' para reunir estimativas de probabilidade. Definimos o estado aleat√≥rio para '0' para embaralhar os dados para obter probabilidades.

### Exerc√≠cio - aplique um Linear SVC

Comece criando um array de classificadores. Voc√™ ir√° adicionar progressivamente a esse array conforme testamos.

1. Comece com um Linear SVC:

    ```python
    C = 10
    # Criar diferentes classificadores.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Treine seu modelo usando o Linear SVC e imprima um relat√≥rio:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    O resultado √© bem bom:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificador K-Neighbors

K-Neighbors faz parte da fam√≠lia "neighbors" de m√©todos de ML, que podem ser usados tanto para aprendizagem supervisionada quanto n√£o supervisionada. Neste m√©todo, um n√∫mero predefinido de pontos √© criado e os dados s√£o agrupados em torno desses pontos para que r√≥tulos generalizados possam ser previstos para os dados.

### Exerc√≠cio - aplique o classificador K-Neighbors

O classificador anterior foi bom e funcionou bem com os dados, mas talvez possamos obter uma melhor precis√£o. Experimente um classificador K-Neighbors.

1. Adicione uma linha ao seu array de classificadores (adicione uma v√≠rgula ap√≥s o item Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    O resultado √© um pouco pior:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Saiba mais sobre [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificador Support Vector

Os classificadores Support-Vector fazem parte da fam√≠lia de m√©todos de ML [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) usados para tarefas de classifica√ß√£o e regress√£o. SVMs "mapeiam exemplos de treinamento para pontos no espa√ßo" para maximizar a dist√¢ncia entre duas categorias. Dados subsequentes s√£o mapeados neste espa√ßo para que sua categoria possa ser prevista.

### Exerc√≠cio - aplique um classificador Support Vector

Vamos tentar uma precis√£o um pouco melhor com um classificador Support Vector.

1. Adicione uma v√≠rgula ap√≥s o item K-Neighbors e depois adicione esta linha:

    ```python
    'SVC': SVC(),
    ```

    O resultado √© bastante bom!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Saiba mais sobre [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificadores Ensemble

Vamos seguir o caminho at√© o fim, embora o teste anterior tenha sido muito bom. Vamos tentar alguns 'Classificadores Ensemble', especificamente Random Forest e AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

O resultado √© muito bom, especialmente para Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Saiba mais sobre [Classificadores Ensemble](https://scikit-learn.org/stable/modules/ensemble.html)

Este m√©todo de Machine Learning "combina as previs√µes de v√°rios estimadores base" para melhorar a qualidade do modelo. No nosso exemplo, usamos Random Trees e AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), um m√©todo de m√©dia, constr√≥i uma 'floresta' de '√°rvores de decis√£o' infundidas com aleatoriedade para evitar overfitting. O par√¢metro n_estimators √© definido para o n√∫mero de √°rvores.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajusta um classificador a um conjunto de dados e ent√£o ajusta c√≥pias desse classificador ao mesmo conjunto de dados. Ele foca nos pesos dos itens classificados incorretamente e ajusta o ajuste para o pr√≥ximo classificador corrigir.

---

## üöÄDesafio

Cada uma dessas t√©cnicas tem um grande n√∫mero de par√¢metros que voc√™ pode ajustar. Pesquise os par√¢metros padr√£o de cada uma e pense sobre o que ajustar esses par√¢metros significaria para a qualidade do modelo.

## [Quiz p√≥s-lectura](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Autoestudo

H√° muita terminologia nestas li√ß√µes, ent√£o reserve um minuto para revisar [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de termos √∫teis!

## Tarefa

[Brincando com par√¢metros](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->