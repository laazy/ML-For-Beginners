# Mutfak sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± 2

Bu ikinci sÄ±nÄ±flandÄ±rma dersinde, sayÄ±sal verileri sÄ±nÄ±flandÄ±rmanÄ±n daha fazla yolunu keÅŸfedeceksiniz. AyrÄ±ca, bir sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± diÄŸerine tercih etmenin sonuÃ§larÄ±nÄ± Ã¶ÄŸreneceksiniz.

## [Ders Ã¶ncesi quiz](https://ff-quizzes.netlify.app/en/ml/)

### Ã–nkoÅŸul

Ã–nceki dersleri tamamladÄ±ÄŸÄ±nÄ±zÄ± ve temizlenmiÅŸ bir veri setine sahip olduÄŸunuzu varsayÄ±yoruz. Bu veri seti, bu 4 derslik klasÃ¶rÃ¼n kÃ¶kÃ¼nde `data` klasÃ¶rÃ¼nde _cleaned_cuisines.csv_ olarak yer alÄ±yor.

### HazÄ±rlÄ±k

_notebook.ipynb_ dosyanÄ±z temizlenmiÅŸ veri seti ile yÃ¼klendi ve model oluÅŸturma sÃ¼reci iÃ§in X ve y veri Ã§erÃ§evelerine bÃ¶lÃ¼ndÃ¼.

## Bir sÄ±nÄ±flandÄ±rma haritasÄ±

Ã–nceden, Microsoft'un hÄ±zlÄ± baÅŸvuru sayfasÄ±nÄ± kullanarak veri sÄ±nÄ±flandÄ±rmada sahip olduÄŸunuz Ã§eÅŸitli seÃ§enekler hakkÄ±nda bilgi edindiniz. Scikit-learn benzer ancak daha ayrÄ±ntÄ±lÄ± bir hÄ±zlÄ± baÅŸvuru sunar ve bu, tahmin edicilerinizi (sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±n baÅŸka bir terimi) daha da daraltmanÄ±za yardÄ±mcÄ± olabilir:

![Scikit-learn'den ML HaritasÄ±](../../../../translated_images/tr/map.e963a6a51349425a.webp)
> Ä°pucu: [bu haritayÄ± Ã§evrimiÃ§i ziyaret edin](https://scikit-learn.org/stable/tutorial/machine_learning_map/) ve dokÃ¼mantasyona okumak iÃ§in yol boyunca tÄ±klayÄ±n.

### Plan

Bu harita, verilerinizi net olarak anladÄ±ÄŸÄ±nÄ±zda Ã§ok faydalÄ±dÄ±r, Ã§Ã¼nkÃ¼ karar vermek iÃ§in yollarÄ±nda 'yÃ¼rÃ¼yebilirsiniz':

- 50'den fazla Ã¶rneÄŸimiz var
- Bir kategori tahmin etmek istiyoruz
- Etiketli verilerimiz var
- 100K'dan daha az Ã¶rnek var
- âœ¨ Lineer SVC seÃ§ebiliriz
- EÄŸer bu iÅŸe yaramazsa, sayÄ±sal verimiz olduÄŸundan
    - âœ¨ KNeighbors SÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± deneyebiliriz
      - EÄŸer bu da iÅŸe yaramazsa, âœ¨ SVC ve âœ¨ Topluluk SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±nÄ± deneyin

Takip etmek iÃ§in Ã§ok faydalÄ± bir yol.

## AlÄ±ÅŸtÄ±rma - veriyi bÃ¶l

Bu yolu izleyerek kullanmak iÃ§in bazÄ± kÃ¼tÃ¼phaneleri iÃ§e aktarmayla baÅŸlamalÄ±yÄ±z.

1. Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±n:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

2. EÄŸitim ve test verilerinizi bÃ¶lÃ¼n:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Lineer SVC sÄ±nÄ±flandÄ±rÄ±cÄ±

Destek VektÃ¶r KÃ¼meleme (SVC), ML tekniklerinin Destek VektÃ¶r makineleri ailesinin bir Ã¼yesidir (aÅŸaÄŸÄ±da bunlar hakkÄ±nda daha fazla bilgi edinin). Bu yÃ¶ntemde, etiketleri nasÄ±l kÃ¼meleneceÄŸine karar vermek iÃ§in bir 'kernel' seÃ§ebilirsiniz. 'C' parametresi, parametrelerin etkisini dÃ¼zenleyen 'regularizasyon'u ifade eder. Kernel [Ã§eÅŸitli](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) olabilir; burada lineer SVC'den yararlanmak iÃ§in 'linear' olarak ayarladÄ±k. Probability varsayÄ±lan olarak 'false' tur; burada olasÄ±lÄ±k tahminlerini toplamak iÃ§in 'true' olarak ayarladÄ±k. Verileri karÄ±ÅŸtÄ±rmak iÃ§in random state '0' olarak ayarlandÄ±.

### AlÄ±ÅŸtÄ±rma - lineer SVC uygula

Ã–ncelikle bir sÄ±nÄ±flandÄ±rÄ±cÄ±lar dizisi oluÅŸturun. Test ettikÃ§e bu diziye kademeli olarak ekleme yapacaksÄ±nÄ±z.

1. Lineer SVC ile baÅŸlayÄ±n:

    ```python
    C = 10
    # FarklÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±lar oluÅŸturun.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Modelinizi Lineer SVC kullanarak eÄŸitin ve bir rapor yazdÄ±rÄ±n:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    SonuÃ§ oldukÃ§a iyi:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-KomÅŸu sÄ±nÄ±flandÄ±rÄ±cÄ±

K-KomÅŸu, hem denetimli hem de denetimsiz Ã¶ÄŸrenmede kullanÄ±labilen "komÅŸular" ailesinin bir parÃ§asÄ±dÄ±r. Bu yÃ¶ntemde, Ã¶nceden tanÄ±mlanmÄ±ÅŸ sayÄ±da nokta oluÅŸturulur ve veriler bu noktalarÄ±n etrafÄ±nda toplanÄ±r, bÃ¶ylece veri iÃ§in genelleÅŸtirilmiÅŸ etiketler tahmin edilebilir.

### AlÄ±ÅŸtÄ±rma - K-KomÅŸu sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± uygula

Ã–nceki sÄ±nÄ±flandÄ±rÄ±cÄ± iyiydi ve veri ile iyi Ã§alÄ±ÅŸtÄ±, ancak belki daha iyi doÄŸruluk elde edebiliriz. Bir K-KomÅŸu sÄ±nÄ±flandÄ±rÄ±cÄ± deneyin.

1. SÄ±nÄ±flandÄ±rÄ±cÄ± dizinize bir satÄ±r ekleyin (Lineer SVC maddesinden sonra virgÃ¼l koyun):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    SonuÃ§ biraz daha kÃ¶tÃ¼:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors) hakkÄ±nda bilgi edinin

## Destek VektÃ¶r SÄ±nÄ±flandÄ±rÄ±cÄ±

Destek VektÃ¶r sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±, sÄ±nÄ±flandÄ±rma ve regresyon gÃ¶revleri iÃ§in kullanÄ±lan ML yÃ¶ntemlerinin [Destek VektÃ¶r Makinesi](https://wikipedia.org/wiki/Support-vector_machine) ailesinin bir parÃ§asÄ±dÄ±r. SVM'ler "eÄŸitim Ã¶rneklerini uzaydaki noktalara eÅŸler" ve iki kategori arasÄ±ndaki mesafeyi maksimize eder. Sonraki veriler bu uzaya eÅŸlenir ve kategorileri tahmin edilir.

### AlÄ±ÅŸtÄ±rma - Destek VektÃ¶r SÄ±nÄ±flandÄ±rÄ±cÄ± uygula

Destek VektÃ¶r SÄ±nÄ±flandÄ±rÄ±cÄ± ile biraz daha iyi doÄŸruluk elde etmeye Ã§alÄ±ÅŸalÄ±m.

1. K-KomÅŸu maddesinden sonra virgÃ¼l koyun ve sonra bu satÄ±rÄ± ekleyin:

    ```python
    'SVC': SVC(),
    ```

    SonuÃ§ oldukÃ§a iyi!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… [Destek VektÃ¶rler](https://scikit-learn.org/stable/modules/svm.html#svm) hakkÄ±nda bilgi edinin

## Topluluk SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±

Ã–nceki test oldukÃ§a iyi olmasÄ±na raÄŸmen, yolu sonuna kadar takip edelim. BazÄ± 'Topluluk SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±' deneyelim, Ã¶zellikle Random Forest ve AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

SonuÃ§ Ã§ok iyi, Ã¶zellikle Random Forest iÃ§in:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… [Topluluk SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±](https://scikit-learn.org/stable/modules/ensemble.html) hakkÄ±nda bilgi edinin

Bu Makine Ã–ÄŸrenimi yÃ¶ntemi, "birkaÃ§ temel tahmin edicinin tahminlerini birleÅŸtirerek" model kalitesini artÄ±rÄ±r. Ã–rneÄŸimizde Rastgele AÄŸaÃ§lar ve AdaBoost kullandÄ±k.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), bir ortalama yÃ¶ntemi, aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in rastgelelikle donatÄ±lmÄ±ÅŸ 'karar aÄŸaÃ§larÄ±' 'ormanÄ±' oluÅŸturur. n_estimators parametresi aÄŸaÃ§ sayÄ±sÄ±na ayarlanÄ±r.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), bir sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± verisetine uyar ve sonra bu sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n kopyalarÄ±nÄ± aynÄ± verisetine uyar. YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸ Ã¶ÄŸelerin aÄŸÄ±rlÄ±klarÄ±na odaklanÄ±r ve sonraki sÄ±nÄ±flandÄ±rÄ±cÄ±nÄ±n uymasÄ±nÄ± dÃ¼zeltmek iÃ§in ayarlar.

---

## ğŸš€Meydan Okuma

Bu tekniklerin her birinin ayarlanabilecek Ã§ok sayÄ±da parametresi vardÄ±r. Her birinin varsayÄ±lan parametrelerini araÅŸtÄ±rÄ±n ve bu parametrelerin deÄŸiÅŸtirilmesinin model kalitesi iÃ§in ne anlama geleceÄŸini dÃ¼ÅŸÃ¼nÃ¼n.

## [Ders sonrasÄ± quiz](https://ff-quizzes.netlify.app/en/ml/)

## Tekrar & Kendi Kendine Ã‡alÄ±ÅŸma

Bu derslerde Ã§ok fazla jargon var, bu yÃ¼zden faydalÄ± terimler [bu listeyi](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) gÃ¶zden geÃ§irmek iÃ§in bir dakika ayÄ±rÄ±n!

## Ã–dev

[Parametre oyunu](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Feragatname**:
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen gÃ¶z Ã¶nÃ¼nde bulundurun. Orijinal belge, kendi ana dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu ortaya Ã§Ä±kabilecek herhangi bir yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumdan sorumlu deÄŸiliz.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->