# Klasyfikatory kuchni 2

W tej drugiej lekcji klasyfikacji poznasz wiÄ™cej sposobÃ³w klasyfikacji danych numerycznych. Dowiesz siÄ™ rÃ³wnieÅ¼ o konsekwencjach wyboru jednego klasyfikatora zamiast drugiego.

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

### Wymagania wstÄ™pne

ZakÅ‚adamy, Å¼e ukoÅ„czyÅ‚eÅ› poprzednie lekcje i masz wyczyszczony zestaw danych w folderze `data` o nazwie _cleaned_cuisines.csv_ w katalogu gÅ‚Ã³wnym tego folderu z 4 lekcjami.

### Przygotowanie

WczytaliÅ›my do twojego pliku _notebook.ipynb_ wyczyszczony zestaw danych i podzieliliÅ›my go na ramki danych X i y, gotowe do procesu budowania modelu.

## Mapa klasyfikacji

WczeÅ›niej poznaÅ‚eÅ› rÃ³Å¼ne opcje klasyfikacji danych za pomocÄ… Å›ciÄ…gawki Microsoftu. Scikit-learn oferuje podobnÄ…, ale bardziej szczegÃ³Å‚owÄ… Å›ciÄ…gawkÄ™, ktÃ³ra moÅ¼e jeszcze bardziej zawÄ™ziÄ‡ wybÃ³r twoich estymatorÃ³w (inna nazwa dla klasyfikatorÃ³w):

![ML Map from Scikit-learn](../../../../translated_images/pl/map.e963a6a51349425a.webp)
> WskazÃ³wka: [odwiedÅº tÄ™ mapÄ™ online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) i klikaj po Å›cieÅ¼ce, aby czytaÄ‡ dokumentacjÄ™.

### Plan

Ta mapa jest bardzo pomocna, gdy masz jasne zrozumienie swoich danych, poniewaÅ¼ moÅ¼esz 'wÄ™drowaÄ‡' jej Å›cieÅ¼kami do decyzji:

- Mamy >50 prÃ³bek
- Chcemy przewidzieÄ‡ kategoriÄ™
- Mamy dane oznaczone
- Mamy mniej niÅ¼ 100 tysiÄ™cy prÃ³bek
- âœ¨ MoÅ¼emy wybraÄ‡ Linear SVC
- JeÅ›li to nie zadziaÅ‚a, poniewaÅ¼ mamy dane numeryczne
    - MoÅ¼emy sprÃ³bowaÄ‡ âœ¨ KNeighbors Classifier
      - JeÅ›li to nie zadziaÅ‚a, sprÃ³buj âœ¨ SVC i âœ¨ Ensemble Classifiers

To bardzo pomocna Å›cieÅ¼ka do podÄ…Å¼ania.

## Ä†wiczenie - podziaÅ‚ danych

PodÄ…Å¼ajÄ…c tÄ… Å›cieÅ¼kÄ…, powinniÅ›my zaczÄ…Ä‡ od zaimportowania kilku potrzebnych bibliotek.

1. Zaimportuj potrzebne biblioteki:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Podziel dane na treningowe i testowe:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Klasyfikator Linear SVC

Support-Vector clustering (SVC) jest technikÄ… z rodziny maszyn wektorÃ³w noÅ›nych (ang. Support-Vector machines), o ktÃ³rych dowiesz siÄ™ wiÄ™cej poniÅ¼ej. W tej metodzie moÅ¼esz wybraÄ‡ 'jÄ…dro' decydujÄ…ce, jak grupowaÄ‡ etykiety. Parametr 'C' odnosi siÄ™ do 'regularizacji', ktÃ³ra reguluje wpÅ‚yw parametrÃ³w. JÄ…dro moÅ¼e byÄ‡ jednym z [wielu](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); tutaj ustawiamy je na 'linear', aby wykorzystaÄ‡ liniowy SVC. Parametr probability domyÅ›lnie jest 'false'; tutaj ustawiamy na 'true', aby zebraÄ‡ oszacowania prawdopodobieÅ„stwa. Ustawiamy stan losowy na '0', aby przetasowaÄ‡ dane, co pozwala otrzymaÄ‡ prawdopodobieÅ„stwa.

### Ä†wiczenie - zastosuj Linear SVC

Zacznij od stworzenia tablicy klasyfikatorÃ³w. BÄ™dziesz jÄ… stopniowo uzupeÅ‚niaÄ‡ podczas testÃ³w.

1. Zacznij od Linear SVC:

    ```python
    C = 10
    # UtwÃ³rz rÃ³Å¼ne klasyfikatory.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Naucz model przy uÅ¼yciu Linear SVC i wydrukuj raport:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Wynik jest caÅ‚kiem dobry:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Klasyfikator K-Neighbors

K-Neighbors naleÅ¼y do rodziny metod "sÄ…siadÃ³w", ktÃ³re moÅ¼na stosowaÄ‡ zarÃ³wno w uczeniu nadzorowanym, jak i nienadzorowanym. W tej metodzie tworzona jest zdefiniowana liczba punktÃ³w, a dane sÄ… grupowane wokÃ³Å‚ tych punktÃ³w, tak aby moÅ¼na byÅ‚o przewidzieÄ‡ uogÃ³lnione etykiety dla danych.

### Ä†wiczenie - zastosuj klasyfikator K-Neighbors

Poprzedni klasyfikator dziaÅ‚aÅ‚ dobrze z danymi, ale moÅ¼e uzyskamy lepszÄ… dokÅ‚adnoÅ›Ä‡. SprÃ³buj klasyfikatora K-Neighbors.

1. Dodaj liniÄ™ do tablicy klasyfikatorÃ³w (dodaj przecinek po elemencie Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Wynik jest nieco gorszy:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… Dowiedz siÄ™ wiÄ™cej o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Klasyfikator Support Vector

Klasyfikatory support-vector sÄ… czÄ™Å›ciÄ… rodziny metod [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) stosowanych do zadaÅ„ klasyfikacji i regresji. SVM â€mapuje przykÅ‚ady treningowe na punkty w przestrzeniâ€, aby zmaksymalizowaÄ‡ odlegÅ‚oÅ›Ä‡ miÄ™dzy dwiema kategoriami. Kolejne dane sÄ… mapowane do tej przestrzeni, aby moÅ¼na byÅ‚o przewidzieÄ‡ ich kategoriÄ™.

### Ä†wiczenie - zastosuj Support Vector Classifier

SprÃ³bujmy uzyskaÄ‡ nieco lepszÄ… dokÅ‚adnoÅ›Ä‡ za pomocÄ… Support Vector Classifier.

1. Dodaj przecinek po elemencie K-Neighbors, a nastÄ™pnie dodaj tÄ™ liniÄ™:

    ```python
    'SVC': SVC(),
    ```

    Wynik jest caÅ‚kiem dobry!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… Dowiedz siÄ™ wiÄ™cej o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Klasyfikatory zespoÅ‚owe (Ensemble)

PodÄ…Å¼my Å›cieÅ¼kÄ… aÅ¼ do koÅ„ca, chociaÅ¼ poprzedni test byÅ‚ caÅ‚kiem dobry. SprÃ³bujmy kilku 'klasyfikatorÃ³w zespoÅ‚owych', w szczegÃ³lnoÅ›ci Random Forest i AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Wynik jest bardzo dobry, szczegÃ³lnie dla Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… Dowiedz siÄ™ o [Klasyfikatorach zespoÅ‚owych](https://scikit-learn.org/stable/modules/ensemble.html)

Ta metoda uczenia maszynowego â€Å‚Ä…czy predykcje kilku bazowych estymatorÃ³wâ€, aby poprawiÄ‡ jakoÅ›Ä‡ modelu. W naszym przykÅ‚adzie uÅ¼yliÅ›my drzew losowych i AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), metoda uÅ›redniajÄ…ca, buduje 'las' 'drzew decyzyjnych' z elementem losowoÅ›ci, aby uniknÄ…Ä‡ przeuczenia. Parametr n_estimators okreÅ›la liczbÄ™ drzew.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) dopasowuje klasyfikator do zestawu danych, a nastÄ™pnie dopasowuje kopie tego klasyfikatora do tego samego zestawu. Skupia siÄ™ na wagach bÅ‚Ä™dnie sklasyfikowanych elementÃ³w i dostosowuje dopasowanie dla kolejnego klasyfikatora, aby to poprawiÄ‡.

---

## ğŸš€Wyzwanie

KaÅ¼da z tych technik ma duÅ¼Ä… liczbÄ™ parametrÃ³w, ktÃ³re moÅ¼esz dostosowaÄ‡. Zbadaj domyÅ›lne parametry kaÅ¼dego z nich i zastanÃ³w siÄ™, co zmiana tych parametrÃ³w mogÅ‚aby oznaczaÄ‡ dla jakoÅ›ci modelu.

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ml/)

## PowtÃ³rka i samodzielna nauka

W tych lekcjach jest duÅ¼o Å¼argonu, wiÄ™c poÅ›wiÄ™Ä‡ chwilÄ™ na przeglÄ…d [tej listy](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) przydatnej terminologii!

## Zadanie

[Zabawa z parametrami](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu automatycznej usÅ‚ugi tÅ‚umaczeniowej [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku macierzystym naleÅ¼y uznawaÄ‡ za ÅºrÃ³dÅ‚o autorytatywne. W przypadku krytycznych informacji zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->