# Sukurkite regresijos modelÄ¯ naudodami Scikit-learn: regresija keturiais bÅ«dais

## PradedanÄiÅ³jÅ³ pastaba

LinijinÄ— regresija naudojama, kai norime nuspÄ—ti **skaitinÄ™ reikÅ¡mÄ™** (pavyzdÅ¾iui, namo kainÄ…, temperatÅ«rÄ… ar pardavimus).
Ji veikia ieÅ¡kodama tiesÄ—s, kuri geriausiai atspindi ryÅ¡Ä¯ tarp Ä¯vesties poÅ¾ymiÅ³ ir iÅ¡vesties.

Å iame pamokoje daugiausia dÄ—mesio skiriame koncepcijos supratimui, prieÅ¡ nagrinÄ—jant paÅ¾angesnes regresijos technikas.
![LinijinÄ— ir polininÄ— regresija infografika](../../../../translated_images/lt/linear-polynomial.5523c7cb6576ccab.webp)
> Infografika autoriaus [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [PrieÅ¡paskaitinis testas](https://ff-quizzes.netlify.app/en/ml/)

> ### [Å i pamoka taip pat prieinama R kalba!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Ä®vadas

Iki Å¡iol jÅ«s susipaÅ¾inote, kas yra regresija, naudodami pavyzdinius duomenis iÅ¡ moliÅ«gÅ³ kainÅ³ rinkinio, kurÄ¯ naudosime per visÄ… pamokÄ…. Taip pat juos vizualizavote naudodami Matplotlib.

Dabar esate pasiruoÅ¡Ä™ giliau gilintis Ä¯ regresijÄ… ML kontekste. Nors vizualizacija leidÅ¾ia geriau suprasti duomenis, tikroji MaÅ¡ininio Mokymosi galia kyla iÅ¡ _modeliÅ³ mokymo_. Modeliai mokomi pagal istorinÄ¯ duomenÅ³ rinkinÄ¯, kad automatiÅ¡kai uÅ¾fiksuotÅ³ duomenÅ³ priklausomybes ir leistÅ³ prognozuoti rezultatus naujiems, anksÄiau nematytiems duomenims.

Å ioje pamokoje suÅ¾inosite daugiau apie du regresijos tipus: _pagrindinÄ™ linijinÄ™ regresijÄ…_ ir _polininÄ™ regresijÄ…_, taip pat apie dalÄ¯ matematikos, esanÄios Å¡iÅ³ metodÅ³ pagrindu. Å ie modeliai leis mums prognozuoti moliÅ«gÅ³ kainas, remiantis skirtingais Ä¯vesties duomenimis.

[![ML pradedantiesiems - LinijinÄ—s regresijos supratimas](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML pradedantiesiems - LinijinÄ—s regresijos supratimas")

> ğŸ¥ Paspauskite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… linijinÄ—s regresijos apÅ¾valgÄ….

> Per visÄ… Å¡iÄ… kurso programÄ… mes laikome, kad matematikos Å¾inios minimalios ir stengiamÄ—s jas padaryti prieinamas studentams iÅ¡ kitÅ³ sriÄiÅ³, todÄ—l atkreipkite dÄ—mesÄ¯ Ä¯ pastabas, ğŸ§® iÅ¡kylamuosius langus, diagramas ir kitus mokymosi Ä¯rankius, padedanÄius suvokimui.

### Reikalavimai

Jau turÄ—tumÄ—te bÅ«ti susipaÅ¾inÄ™ su moliÅ«gÅ³ duomenÅ³ struktÅ«ra, kuriÄ… nagrinÄ—jame. JÄ… galite rasti iÅ¡ anksto Ä¯keltÄ… ir iÅ¡valytÄ… Å¡ios pamokos _notebook.ipynb_ faile. Faile moliÅ«gÅ³ kaina rodoma uÅ¾ bushelÄ¯ naujame duomenÅ³ rinkinyje. UÅ¾tikrinkite, kad galite paleisti Å¡iuos uÅ¾raÅ¡Å³ knygeliÅ³ failus Visual Studio Code branduoliuose.

### ParuoÅ¡imas

Primename, kad duomenis Ä¯keliame tam, kad galÄ—tume uÅ¾duoti klausimus.

- Kada geriausia pirkti moliÅ«gus?
- Kokios kainos galiu tikÄ—tis uÅ¾ ieÅ¡minius moliÅ«gus dÄ—Å¾Ä—je?
- Ar pirkti juos per pusÄ—s bushelio krepÅ¡ius, ar per 1 1/9 bushelio dÄ—Å¾utes?
Toliau gilinamÄ—s Ä¯ Å¡iuos duomenis.

Praeitoje pamokoje sukÅ«rÄ—te Pandas duomenÅ³ rinkinÄ¯ ir uÅ¾pildÄ—te jÄ¯ dalimi originaliÅ³ duomenÅ³, standartizuodami kainas pagal bushelÄ¯. TaÄiau tai leido surinkti tik apie 400 duomenÅ³ taÅ¡kÅ³ ir tik rudens mÄ—nesiams.

PaÅ¾iÅ«rÄ—kite Ä¯ duomenis, kuriuos iÅ¡ anksto Ä¯kÄ—lÄ—me Å¡ios pamokos uÅ¾raÅ¡Å³ knygelÄ—je. Duomenys Ä¯kelti ir parodytas pradinis sklaidos grafikas rodo mÄ—nesio duomenis. GalbÅ«t galime dar Å¡iek tiek plaÄiau paÅ¾velgti Ä¯ duomenÅ³ pobÅ«dÄ¯, juos dar labiau iÅ¡valydami.

## LinijinÄ—s regresijos tiesÄ—

Kaip suÅ¾inojote 1-pamokoje, linijinÄ—s regresijos uÅ¾duotis yra nubraiÅ¾yti tiesÄ™, kuri:

- **Atvaizduoja kintamÅ³jÅ³ ryÅ¡ius**. Parodo sÄ…ryÅ¡Ä¯ tarp kintamÅ³jÅ³
- **LeidÅ¾ia prognozuoti**. Tiksliai numatyti, kur naujas duomenÅ³ taÅ¡kas kris santykyje su ta tiesÄ—.

 Ä®prasta **maÅ¾iausiÅ³ kvadratÅ³ regresijoje** pieÅ¡ti tokÄ¯ tiesiÅ³jÄ¯ grafikÄ…. Terminas â€MaÅ¾iausiÅ³ kvadratÅ³â€œ reiÅ¡kia procesÄ…, kurio metu minimalizuojama bendroji klaida modelyje. Kiekvienam duomenÅ³ taÅ¡kui matuojame vertikalÅ³ atstumÄ… (vadinamÄ… likuÄiu) tarp tikrosios reikÅ¡mÄ—s ir mÅ«sÅ³ regresijos linijos.

Å iuos atstumus kvadratuojame dÄ—l dviejÅ³ pagrindiniÅ³ prieÅ¾asÄiÅ³:

1. **DydÅ¾io svarba, o ne kryptis:** Norime, kad klaida -5 bÅ«tÅ³ vertinama taip pat kaip +5. Kvadratuojant visos reikÅ¡mÄ—s tampa teigiamos.

2. **IÅ¡skirtiniÅ³ atvejÅ³ bausmÄ—:** Kvadratuojant didelÄ—s klaidos Ä¯gauna didesnÄ¯ svorÄ¯, dÄ—l to tiesÄ— stengiasi bÅ«ti arÄiau toli esanÄiÅ³ taÅ¡kÅ³.

Tada sudedame visus kvadratuotus atstumus. MÅ«sÅ³ tikslas â€“ rasti tÄ… tiesÄ™, kuri minimizuoja Å¡Ä¯ sumÄ… (maÅ¾iausia Ä¯manoma reikÅ¡mÄ—) â€“ todÄ—l vadinama â€maÅ¾iausiÅ³ kvadratÅ³â€œ metodu.

> **ğŸ§® Parodykite man matematikÄ…**  
>  
> Å i tiesÄ—, vadinama _geriausiai pritaikyta tiesÄ—_, gali bÅ«ti iÅ¡reikÅ¡ta [lygtimi](https://en.wikipedia.org/wiki/Simple_linear_regression):  
>  
> ```
> Y = a + bX
> ```
>
> `X` yra 'paaiÅ¡kinamasis kintamasis'. `Y` yra 'priklausomas kintamasis'. TiesÄ—s nuolydis yra `b`, o `a` yra y-interceptas, kuris reiÅ¡kia `Y` reikÅ¡mÄ™, kai `X = 0`.  
>
>![nuolydÅ¾io skaiÄiavimas](../../../../translated_images/lt/slope.f3c9d5910ddbfcf9.webp)
>
> Pirmiausia apskaiÄiuojame nuolydÄ¯ `b`. Infografika autoriaus [Jen Looper](https://twitter.com/jenlooper)
>
> Kitaip tariant, kalbant apie mÅ«sÅ³ moliÅ«gÅ³ duomenÅ³ pradinÄ¯ klausimÄ…: â€prognozuoti moliÅ«gÅ³ kainÄ… uÅ¾ bushelÄ¯ pagal mÄ—nesÄ¯â€œ, `X` reikÅ¡tÅ³ kainÄ…, o `Y` bÅ«tÅ³ pardavimo mÄ—nuo.
>
>![lygtys uÅ¾baigimas](../../../../translated_images/lt/calculation.a209813050a1ddb1.webp)
>
> ApskaiÄiuokite `Y` reikÅ¡mÄ™. Jei mokate apie 4 USD, tai turi bÅ«ti balandis! Infografika autoriaus [Jen Looper](https://twitter.com/jenlooper)
>
> Matematikos formule turi parodyti linijos nuolydÄ¯, kuris taip pat priklauso nuo sankirtos, arba kur `Y` yra, kai `X=0`.
>
> Galite stebÄ—ti skaiÄiavimo metodÄ… Å¡ioje svetainÄ—je [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Taip pat apsilankykite [Å iame maÅ¾iausiÅ³ kvadratÅ³ skaiÄiuoklyje](https://www.mathsisfun.com/data/least-squares-calculator.html), kad pamatytumÄ—te, kaip skaiÄiÅ³ vertÄ—s veikia tiesÄ™.

## Koreliacija

Dar vienas svarbus terminas yra **koreliacijos koeficientas** tarp tam tikrÅ³ X ir Y kintamÅ³jÅ³. Naudodami sklaidos grafikÄ… greitai galite vizualizuoti Å¡Ä¯ koeficientÄ…. Grafikas su duomenÅ³ taÅ¡kais, susitelkusiais Ä¯ tvarkingÄ… linijÄ…, turi aukÅ¡tÄ… koreliacijÄ…, o su duomenÅ³ taÅ¡kais iÅ¡sibarsÄiusiais tarp X ir Y - Å¾emÄ… koreliacijÄ….

Geras linijinÄ—s regresijos modelis turi bÅ«ti toks, kurio koreliacijos koeficientas pagal maÅ¾iausiÅ³ kvadratÅ³ regresijos metodÄ… yra aukÅ¡tas (arÄiau 1 nei 0).

âœ… Paleiskite Å¡ios pamokos uÅ¾raÅ¡Å³ knygelÄ™ ir paÅ¾iÅ«rÄ—kite Ä¯ Monthâ€“Price sklaidos grafikÄ…. Ar duomenys, susiejantys mÄ—nesÄ¯ su moliÅ«gÅ³ kainomis, atrodo turintys aukÅ¡tÄ… ar Å¾emÄ… koreliacijÄ… pagal jÅ«sÅ³ vizualinÄ™ sklaidos grafikÄ…? Ar tai pasikeiÄia, jei vietoje `Month` panaudojate smulkesnÄ¯ matavimÄ…, pvz., *metÅ³ dienÄ…* (t.y. dienÅ³ skaiÄiÅ³ nuo metÅ³ pradÅ¾ios)?

Toliau pateiktame kode skelbiame, kad duomenys buvo sutvarkyti ir mes turime duomenÅ³ rÄ—melÄ¯ `new_pumpkins`, panaÅ¡Å³ Ä¯ Å¡Ä¯:

ID | MÄ—nuo | MetÅ³Diena | VeislÄ— | Miestas | PakuotÄ— | Å½emiausia kaina | AukÅ¡Äiausia kaina | Kaina
---|-------|-----------|---------|---------|---------|----------------|------------------|-------
70 | 9     | 267       | PYRAGO TIPO  | BALTIMORA   | 1 1/9 bushelio dÄ—Å¾utÄ—s | 15.0           | 15.0             | 13.636364
71 | 9     | 267       | PYRAGO TIPO  | BALTIMORA   | 1 1/9 bushelio dÄ—Å¾utÄ—s | 18.0           | 18.0             | 16.363636
72 | 10    | 274       | PYRAGO TIPO  | BALTIMORA   | 1 1/9 bushelio dÄ—Å¾utÄ—s | 18.0           | 18.0             | 16.363636
73 | 10    | 274       | PYRAGO TIPO  | BALTIMORA   | 1 1/9 bushelio dÄ—Å¾utÄ—s | 17.0           | 17.0             | 15.454545
74 | 10    | 281       | PYRAGO TIPO  | BALTIMORA   | 1 1/9 bushelio dÄ—Å¾utÄ—s | 15.0           | 15.0             | 13.636364

> DuomenÅ³ valymo kodas yra prieinamas faile [`notebook.ipynb`](notebook.ipynb). Atlikome tuos paÄius valymo Å¾ingsnius kaip ir ankstesnÄ—je pamokoje ir apskaiÄiavome `DayOfYear` stulpelÄ¯ naudodami Å¡iÄ… iÅ¡raiÅ¡kÄ…: 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Dabar, kai suprantate linijinÄ—s regresijos matematinius pagrindus, sukurkime Regresijos modelÄ¯, kad suÅ¾inotume, ar galime prognozuoti, kuri moliÅ«gÅ³ pakuotÄ— turÄ—s geriausias kainas. Kas nors, perkantis moliÅ«gus Å¡ventiniam moliÅ«gÅ³ laukui, norÄ—tÅ³ turÄ—ti Å¡iÄ… informacijÄ…, kad galÄ—tÅ³ optimizuoti moliÅ«gÅ³ pirkimus.

## Koreliacijos paieÅ¡ka

[![ML pradedantiesiems - Koreliacijos paieÅ¡ka: raktas Ä¯ linijinÄ™ regresijÄ…](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML pradedantiesiems - Koreliacijos paieÅ¡ka: raktas Ä¯ linijinÄ™ regresijÄ…")

> ğŸ¥ Paspauskite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… koreliacijos apÅ¾valgÄ….

IÅ¡ ankstesnÄ—s pamokos greiÄiausiai jau matÄ—te, kad vidutinÄ— kainÅ³ tendencija pagal mÄ—nesius atrodo maÅ¾daug taip:

<img alt="VidutinÄ— kaina pagal mÄ—nesÄ¯" src="../../../../translated_images/lt/barchart.a833ea9194346d76.webp" width="50%"/>

Tai rodo, kad turÄ—tÅ³ bÅ«ti kaÅ¾kokia koreliacija, ir galime bandyti apmokyti linijinÄ—s regresijos modelÄ¯ prognozuoti ryÅ¡Ä¯ tarp `Month` ir `Price` arba tarp `DayOfYear` ir `Price`. Å tai sklaidos grafikas, rodantis pastarÄ…jÄ¯ ryÅ¡Ä¯:

<img alt="Sklaidos grafikas: Kaina prieÅ¡ MetÅ³ dienÄ…" src="../../../../translated_images/lt/scatter-dayofyear.bc171c189c9fd553.webp" width="50%" />

PaÅ¾iÅ«rÄ—kime, ar yra koreliacija naudodami funkcijÄ… `corr`:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

Atrodo, kad koreliacija gana maÅ¾a, -0,15 pagal `Month` ir -0,17 pagal `DayOfMonth`, bet gali bÅ«ti kitas svarbus ryÅ¡ys. Atrodo, kad kainÅ³ grupÄ—s atitinka skirtingas moliÅ«gÅ³ veisles. NorÄ—dami patvirtinti Å¡iÄ… hipotezÄ™, nubraiÅ¾ykime kiekvienÄ… moliÅ«gÅ³ kategorijÄ… skirtingomis spalvomis. Paduodami `ax` parametrÄ… funkcijai `scatter`, galime nubraiÅ¾yti visus taÅ¡kus vienoje diagramoje:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Sklaidos grafikas: Kaina prieÅ¡ MetÅ³ dienÄ… su spalvomis" src="../../../../translated_images/lt/scatter-dayofyear-color.65790faefbb9d54f.webp" width="50%" />

MÅ«sÅ³ tyrimas rodo, kad veislÄ— labiau veikia bendrÄ… kainÄ… nei tikroji pardavimo data. Tai galime pamatyti ir juostinÄ—je diagramoje:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="JuostinÄ— diagrama: kaina pagal veislÄ™" src="../../../../translated_images/lt/price-by-variety.744a2f9925d9bcb4.webp" width="50%" />

Tuo tarpu sutelkime dÄ—mesÄ¯ tik Ä¯ vienÄ… moliÅ«gÅ³ veislÄ™, â€˜pie typeâ€™, ir paÅ¾iÅ«rÄ—kime, kokÄ¯ poveikÄ¯ data turi kainai:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Sklaidos grafikas: Kaina prieÅ¡ MetÅ³ dienÄ…, tik pie type" src="../../../../translated_images/lt/pie-pumpkins-scatter.d14f9804a53f927e.webp" width="50%" />

Jei dabar apskaiÄiuosime koreliacijÄ… tarp `Price` ir `DayOfYear` panaudodami funkcijÄ… `corr`, gausime kaÅ¾kÄ… panaÅ¡aus Ä¯ `-0.27` â€“ o tai reiÅ¡kia, kad verta apmokyti prognozuojamÄ… modelÄ¯.

> PrieÅ¡ pradÄ—dami apmokyti linijinÄ—s regresijos modelÄ¯, svarbu Ä¯sitikinti, kad duomenys yra Å¡varÅ«s. LinijinÄ— regresija prastai veikia su trÅ«kstamomis reikÅ¡mÄ—mis, todÄ—l verta paÅ¡alinti visas tuÅ¡Äias langelius:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Kitas bÅ«das - uÅ¾pildyti tuÅ¡Äias reikÅ¡mes atitinkamÅ³ stulpeliÅ³ vidurkiais.

## Paprasta linijinÄ— regresija

[![ML pradedantiesiems - LinijinÄ— ir polininÄ— regresija naudojant Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML pradedantiesiems - LinijinÄ— ir polininÄ— regresija naudojant Scikit-learn")

> ğŸ¥ Paspauskite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… linijinÄ—s ir polininÄ—s regresijos apÅ¾valgÄ….

MÅ«sÅ³ LinijinÄ—s regresijos modelio mokymui naudosime **Scikit-learn** bibliotekÄ….

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

PradÄ—sime atskirdami Ä¯vesties reikÅ¡mes ( poÅ¾ymius) ir laukiamÄ… iÅ¡vestÄ¯ (etiketÄ™) Ä¯ atskirus numpy masyvus:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> Atkreipkite dÄ—mesÄ¯, kad reikÄ—jo atlikti `reshape` su Ä¯vesties duomenimis, kad LinijinÄ—s regresijos paketas suprastÅ³ juos teisingai. LinijinÄ— regresija laukia 2D masyvo kaip Ä¯vesties, kur kiekviena masyvo eilutÄ— atitinka poÅ¾ymiÅ³ vektoriÅ³. MÅ«sÅ³ atveju, kai turime tik vienÄ… Ä¯vestÄ¯, mums reikia masyvo formos NÃ—1, kur N â€“ duomenÅ³ rinkinio dydis.

Tada turime padalinti duomenis Ä¯ mokymo ir testavimo rinkinius, kad galÄ—tume modelÄ¯ patikrinti po mokymo:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Galiausiai, faktinis LinijinÄ—s regresijos modelio mokymas uÅ¾ima tik dvi kodo eilutes. ApibrÄ—Å¾iame `LinearRegression` objektÄ… ir pritaikome jÄ¯ mÅ«sÅ³ duomenims naudodami `fit` metodÄ…:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

`LinearRegression` objektas po `fit` pritaikymo turi visus regresijos koeficientus, prie kuriÅ³ galima prieiti naudodami `.coef_` savybÄ™. MÅ«sÅ³ atveju yra tik vienas koeficientas, kuris turÄ—tÅ³ bÅ«ti maÅ¾daug `-0.017`. Tai reiÅ¡kia, kad kainos, atrodo, Å¡iek tiek krinta laikui bÄ—gant, bet ne per daug, apie 2 centus per dienÄ…. Taip pat galime prieiti prie regresijos susikirtimo su Y aÅ¡imi naudodami `lin_reg.intercept_` â€“ mÅ«sÅ³ atveju jis bus maÅ¾daug `21`, rodantis kainÄ… metÅ³ pradÅ¾ioje.

NorÄ—dami pamatyti, kokia tiksliai yra mÅ«sÅ³ modelio kokybÄ—, galime prognozuoti kainas testiniame duomenÅ³ rinkinyje ir tada pamatuoti, kiek mÅ«sÅ³ prognozÄ—s yra arti tikÄ—tinÅ³ reikÅ¡miÅ³. Tai galima padaryti naudojant vidurinÄ—s kvadratinÄ—s paklaidos (MSE) metrikÄ…, kuri yra visÅ³ kvadratiniÅ³ skirtumÅ³ tarp tikÄ—tinos ir prognozuotos reikÅ¡mÄ—s vidurkis.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```

MÅ«sÅ³ klaida atrodo apie 2 taÅ¡kus, tai apie ~17%. Ne per gera. Kitas modelio kokybÄ—s indikatorius yra **nustatymo koeficientas**, kurÄ¯ galima gauti taip:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
Jei reikÅ¡mÄ— yra 0, tai reiÅ¡kia, kad modelis neatsiÅ¾velgia Ä¯ Ä¯vesties duomenis ir veikia kaip *blogiausias tiesinis prognozuotojas*, kuris tiesiog paima vidutinÄ™ reikÅ¡mÄ™. ReikÅ¡mÄ— 1 reiÅ¡kia, kad galime tobulai prognozuoti visas tikÄ—tinas reikÅ¡mes. MÅ«sÅ³ atveju koeficientas yra apie 0.06, kas yra gan Å¾ema.

Taip pat galime nupieÅ¡ti testinius duomenis kartu su regresijos linija, kad geriau matytume, kaip regresija veikia mÅ«sÅ³ atveju:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="Linear regression" src="../../../../translated_images/lt/linear-results.f7c3552c85b0ed1c.webp" width="50%" />

## PolinominÄ— regresija

Kitas linijinÄ—s regresijos tipas yra polinominÄ— regresija. Nors kartais tarp kintamÅ³jÅ³ yra tiesinÄ— priklausomybÄ— â€“ kuo didesnis moliÅ«nas tÅ«riu, tuo didesnÄ— kaina â€“ kartais Å¡iÅ³ priklausomybiÅ³ negalima nubraiÅ¾yti plokÅ¡tuma ar tiesia linija.

âœ… ÄŒia yra [daugiau pavyzdÅ¾iÅ³](https://online.stat.psu.edu/stat501/lesson/9/9.8) duomenÅ³, kuriems gali tikti polinominÄ— regresija

Dar kartÄ… paÅ¾iÅ«rÄ—kite Ä¯ priklausomybÄ™ tarp Datos ir Kainos. Ar Å¡is taÅ¡kÅ³ debesis bÅ«tinai turÄ—tÅ³ bÅ«ti analizuojamas tiesia linija? Ar kainos negali svyruoti? Tokiu atveju galite iÅ¡bandyti polinominÄ™ regresijÄ….

âœ… Polinomai yra matematiniai iÅ¡raiÅ¡kos, kurios gali susidaryti iÅ¡ vieno ar daugiau kintamÅ³jÅ³ ir koeficientÅ³

PolinominÄ— regresija sukuria iÅ¡lenktÄ… linijÄ…, kad geriau pritaikytÅ³ netiesinius duomenis. MÅ«sÅ³ atveju, jei Ä¯ Ä¯vesties duomenis Ä¯trauksime pakeltÄ… kvadratu `DayOfYear` kintamÄ…jÄ¯, galÄ—sime pritaikyti duomenis parabolÄ—s formai, turinÄiai minimumÄ… metÅ³ viduje.

Scikit-learn turi naudingÄ… [pipeline API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline), leidÅ¾ianÄiÄ… sujungti skirtingus duomenÅ³ apdorojimo Å¾ingsnius. **Pipeline** yra **lankÅ³** seka. MÅ«sÅ³ atveju sukursime pipeline, kuris pirmiausia prideda polinominius poÅ¾ymius prie mÅ«sÅ³ modelio ir tada treniruoja regresijÄ…:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

Naudojant `PolynomialFeatures(2)` reiÅ¡kia, kad Ä¯traukiame visus antro laipsnio polinomus iÅ¡ Ä¯vesties duomenÅ³. MÅ«sÅ³ atveju tai reikÅ¡tÅ³ tik `DayOfYear`<sup>2</sup>, bet turint du kintamuosius X ir Y, bus pridedama X<sup>2</sup>, XY ir Y<sup>2</sup>. Taip pat galime naudoti aukÅ¡tesnio laipsnio polinomus, jei norime.

Pipelines galima naudoti taip pat kaip originalÅ³ `LinearRegression` objektÄ…, t.y. galime pritaikyti `fit` pipeline, o paskui naudoti `predict`, kad gautume prognoziÅ³ rezultatus. ÄŒia pateiktas grafikas, rodantis testinius duomenis ir aproksimacinÄ™ kreivÄ™:

<img alt="Polynomial regression" src="../../../../translated_images/lt/poly-results.ee587348f0f1f60b.webp" width="50%" />

Naudodami polinominÄ™ regresijÄ… galime gauti Å¡iek tiek maÅ¾esnÄ¯ MSE ir didesnÄ¯ nustatymo koeficientÄ…, bet ne Å¾ymiai. Turime atsiÅ¾velgti Ä¯ daugiau poÅ¾ymiÅ³!

> Galite pastebÄ—ti, kad maÅ¾iausios moliÅ«nÅ³ kainos fiksuojamos kaÅ¾kur apie HelovinÄ…. Kaip tai galÄ—tumÄ—te paaiÅ¡kinti?

ğŸƒ Sveikiname, kÄ… tik sukÅ«rÄ—te modelÄ¯, kuris gali padÄ—ti prognozuoti pyraginiÅ³ moliÅ«nÅ³ kainÄ…. Tikriausiai galite tÄ… patÄ¯ padaryti visoms moliÅ«nÅ³ rÅ«Å¡ims, bet tai bÅ«tÅ³ varginanti uÅ¾duotis. Dabar iÅ¡moksime, kaip atsiÅ¾velgti Ä¯ moliÅ«nÅ³ veislÄ™ mÅ«sÅ³ modelyje!

## Kategoriniai poÅ¾ymiai

Idealioje pasaulyje norÄ—tume galÄ—ti prognozuoti kainas skirtingoms moliÅ«nÅ³ veislÄ—ms naudojant tÄ… patÄ¯ modelÄ¯. TaÄiau stulpelis `Variety` yra Å¡iek tiek kitoks nei, pavyzdÅ¾iui, `Month`, nes jame yra ne skaitinÄ—s reikÅ¡mÄ—s. Tokie stulpeliai vadinami **kategoriniais**.

[![ML pradedantiesiems â€“ kategoriniÅ³ poÅ¾ymiÅ³ prognozÄ—s su tiesine regresija](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML pradedantiesiems â€“ kategoriniÅ³ poÅ¾ymiÅ³ prognozÄ—s su tiesine regresija")

> ğŸ¥ Paspauskite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, jei norite trumpÄ… vaizdo Ä¯raÅ¡Ä… apie kategoriniÅ³ poÅ¾ymiÅ³ naudojimÄ….

ÄŒia matote, kaip vidutinÄ— kaina priklauso nuo veislÄ—s:

<img alt="Average price by variety" src="../../../../translated_images/lt/price-by-variety.744a2f9925d9bcb4.webp" width="50%" />

NorÄ—dami atsiÅ¾velgti Ä¯ veislÄ™, pirmiausia turime jÄ… paversti skaitine reikÅ¡me, arba **uÅ¾koduoti** jÄ…. Yra keli bÅ«dai, kaip tai padaryti:

* Paprastas **skaitmeninis kodavimas** sukurs skirtingÅ³ veisliÅ³ lentelÄ™, o tada veislÄ—s pavadinimÄ… pakeis indeksu Å¡ioje lentelÄ—je. Tai nÄ—ra geriausias sprendimas tiesinei regresijai, nes tiesinÄ— regresija naudoja tikrÄ…jÄ… skaitinÄ™ indekso reikÅ¡mÄ™ ir prideda jÄ… prie rezultato pasvÄ—rusi tam tikru koeficientu. MÅ«sÅ³ atveju priklausomybÄ— tarp indekso numerio ir kainos yra aiÅ¡kiai netiesinÄ—, net jei uÅ¾tikrintume, kad indeksai bÅ«tÅ³ iÅ¡dÄ—styti tam tikra tvarka.
* **One-hot kodavimas** pakeis `Variety` stulpelÄ¯ 4 skirtingais stulpeliais, po vienÄ… kiekvienai veislei. Kiekviename stulpelyje bus `1`, jei atitinkamas Ä¯raÅ¡as yra tos veislÄ—s, ir `0` kitu atveju. Tai reiÅ¡kia, kad tiesinÄ—je regresijoje bus keturi koeficientai, po vienÄ… kiekvienai moliÅ«nÅ³ veislei, atsakingi uÅ¾ "pradinÄ™ kainÄ…" (ar tiksliau - "papildomÄ… kainÄ…") konkreÄiai veislei.

Å½emiau pateiktas kodas, rodantis, kaip galima one-hot koduoti veislÄ™:

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

NorÄ—dami apmokyti tiesinÄ™ regresijÄ…, naudodami one-hot koduotÄ… veislÄ™ kaip Ä¯vestÄ¯, tiesiog turime teisingai inicializuoti `X` ir `y` duomenis:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

Likusi kodo dalis tokia pati kaip aukÅ¡Äiau naudota tiesinei regresijai treniruoti. Jei iÅ¡bandysite, pamatysite, kad vidutinÄ— kvadratinÄ— klaida bus maÅ¾daug tokia pati, bet gausime daug didesnÄ¯ nustatymo koeficientÄ… (~77%). NorÄ—dami gauti dar tikslesnes prognozes, galime atsiÅ¾velgti Ä¯ daugiau kategoriniÅ³ poÅ¾ymiÅ³, taip pat Ä¯ skaitinius poÅ¾ymius, tokius kaip `Month` ar `DayOfYear`. NorÄ—dami gauti vienÄ… didelÄ¯ poÅ¾ymiÅ³ masyvÄ…, galime naudoti `join`:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

ÄŒia taip pat atsiÅ¾velgiame Ä¯ `City` ir `Package` tipÄ…, kas duoda MSE 2.84 (10%) ir nustatymo koeficientÄ… 0.94!

## Apibendrinimas

Kad sukurtume geriausiÄ… modelÄ¯, galime naudoti sujungtus (one-hot koduotus kategorinius + skaitinius) duomenis kartu su polinomine regresija. Å tai viso kodo pavyzdys jÅ«sÅ³ patogumui:

```python
# nustatyti mokymo duomenis
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# padaryti treniruoÄiÅ³ ir testavimo skaidymÄ…
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# sukonfigÅ«ruoti ir apmokyti procesÅ³ sekÄ…
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# prognozuoti rezultatus testavimo duomenims
pred = pipeline.predict(X_test)

# apskaiÄiuoti vidutinÄ™ kvadratinÄ™ paklaidÄ… ir determinacijos koeficientÄ…
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Tai turÄ—tÅ³ duoti geriausiÄ… nustatymo koeficientÄ… beveik 97% ir MSE=2.23 (~8% prognozÄ—s klaida).

| Modelis | MSE | Nustatymas |
|---------|-----|------------|
| `DayOfYear` TiesinÄ— | 2.77 (17.2%) | 0.07 |
| `DayOfYear` PolinominÄ— | 2.73 (17.0%) | 0.08 |
| `Variety` TiesinÄ— | 5.24 (19.7%) | 0.77 |
| Visi poÅ¾ymiai TiesinÄ— | 2.84 (10.5%) | 0.94 |
| Visi poÅ¾ymiai PolinominÄ— | 2.23 (8.25%) | 0.97 |

ğŸ† Puikiai! Pamokoje sukÅ«rÄ—te keturis regresijos modelius ir pagerinote modelio kokybÄ™ iki 97%. GalutinÄ—je regresijos dalyje susipaÅ¾insite su logistinÄ™ regresijÄ…, skirtÄ… kategorijoms nustatyti.

---
## ğŸš€IÅ¡Å¡Å«kis

IÅ¡bandykite kelis skirtingus kintamuosius Å¡iame sÄ…siuvinyje, kad pamatytumÄ—te, kaip koreliacija atitinka modelio tikslumÄ….

## [Po paskaitos testas](https://ff-quizzes.netlify.app/en/ml/)

## PerÅ¾iÅ«ra ir savarankiÅ¡kas mokymasis

Å ioje pamokoje iÅ¡mokome apie tiesinÄ™ regresijÄ…. Yra ir kitÅ³ svarbiÅ³ regresijos tipÅ³. Perskaitykite apie Å¾ingsninÄ™, â€ridgeâ€œ, lasso ir elasticnet technikas. Geras kursas, norint suÅ¾inoti daugiau, yra [Stanford statistinio mokymosi kursas](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning)

## UÅ¾duotis

[Sukurti modelÄ¯](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant dirbtinio intelekto vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, atkreipkite dÄ—mesÄ¯, kad automatizuoti vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Svarbiai informacijai rekomenduojame pasitelkti profesionalÅ³ Å¾mogiÅ¡kÄ… vertimÄ…. Mes neatsakome uÅ¾ bet kokius nesusipratimus ar klaidingÄ… interpretacijÄ…, kilusiÄ… naudojant Å¡Ä¯ vertimÄ….
<!-- CO-OP TRANSLATOR DISCLAIMER END -->