# Classifik√°tory kuch√Ω≈à 2

V tejto druhej lekcii klasifik√°cie presk√∫mate ƒèal≈°ie sp√¥soby klasifik√°cie numerick√Ωch d√°t. Tie≈æ sa nauƒç√≠te o d√¥sledkoch v√Ωberu jedn√©ho klasifik√°tora namiesto druh√©ho.

## [Predn√°≈°kov√Ω kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

### Predpoklad

Predpoklad√°me, ≈æe ste dokonƒçili predch√°dzaj√∫ce lekcie a m√°te v zlo≈æke `data` vyƒçisten√∫ d√°tov√∫ sadu s n√°zvom _cleaned_cuisines.csv_ v kore≈àovom adres√°ri tejto ≈°tvorlekciovej zlo≈æky.

### Pr√≠prava

Do v√°≈°ho s√∫boru _notebook.ipynb_ sme naƒç√≠tali vyƒçisten√∫ d√°tov√∫ sadu a rozdelili ju na d√°ta X a y, pripraven√© na proces budovania modelu.

## Mapa klasifik√°cie

Predt√Ωm ste sa dozvedeli o r√¥znych mo≈ænostiach klasifik√°cie d√°t podƒæa Microsoftovej pom√¥cky. Scikit-learn pon√∫ka podobn√∫, no detailnej≈°iu pom√¥cku, ktor√° v√°m m√¥≈æe e≈°te viac z√∫≈æi≈• v√Ωber odhadcov (ƒèal≈°√≠ pojem pre klasifik√°tory):

![ML Map from Scikit-learn](../../../../translated_images/sk/map.e963a6a51349425a.webp)
> Tip: [nav≈°t√≠vte t√∫to mapu online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) a klikajte postupne na ceste, aby ste si preƒç√≠tali dokument√°ciu.

### Pl√°n

T√°to mapa je veƒæmi u≈æitoƒçn√°, keƒè m√°te jasn√∫ predstavu o svojich d√°tach, preto≈æe m√¥≈æete ‚Äûprejs≈•‚Äú jej cestami k rozhodnutiu:

- M√°me >50 vzoriek
- Chceme predpoveda≈• kateg√≥riu
- M√°me oznaƒçen√© d√°ta
- M√°me menej ako 100 tis√≠c vzoriek
- ‚ú® M√¥≈æeme zvoli≈• Line√°rny SVC
- Ak to nefunguje, keƒè≈æe m√°me numerick√© d√°ta
    - M√¥≈æeme sk√∫si≈• ‚ú® KNeighbors Classifier
      - Ak to nefunguje, sk√∫ste ‚ú® SVC a ‚ú® Ensemble Classifiers

Toto je veƒæmi u≈æitoƒçn√° cesta, ktor√∫ sa oplat√≠ sledova≈•.

## Cviƒçenie - rozdelenie d√°t

Podƒæa tejto cesty by sme mali zaƒça≈• importovan√≠m niektor√Ωch kni≈æn√≠c.

1. Importujte potrebn√© kni≈ænice:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Rozdeƒæte tr√©ningov√© a testovacie d√°ta:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Line√°rny SVC klasifik√°tor

Support-Vector clustering (SVC) je podmno≈æina rodiny Support-Vector strojov (SVM) v strojovom uƒçen√≠ (dozviete sa o nich ni≈æ≈°ie). V tejto met√≥de m√¥≈æete zvoli≈• 'kernel' (jadro), ktor√© rozhoduje o tom, ako sa labely zhluku. Parameter 'C' oznaƒçuje 'regulariz√°ciu', ktor√° reguluje vplyv parametrov. Kernel m√¥≈æe by≈• jeden z [niekoƒæk√Ωch](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); tu ho nastavujeme na 'linear', aby sme vyu≈æili line√°rny SVC. Pravdepodobnos≈• je ≈°tandardne 'false'; tu ju nastavujeme na 'true', aby sme z√≠skali odhady pravdepodobnosti. N√°hodn√Ω stav nastavujeme na '0', aby sa d√°ta zamie≈°ali a z√≠skali pravdepodobnosti.

### Cviƒçenie - aplikujte line√°rny SVC

Zaƒçnite vytvoren√≠m poƒæa klasifik√°torov. Budete do neho postupne prid√°va≈• podƒæa testovania.

1. Zaƒçnite s Line√°rnym SVC:

    ```python
    C = 10
    # Vytvorte r√¥zne klasifik√°tory.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Natr√©nujte model pomocou Line√°rneho SVC a vytlaƒçte spr√°vu:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    V√Ωsledok je celkom dobr√Ω:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors klasifik√°tor

K-Neighbors patr√≠ do rodiny met√≥d ‚Äûneighbors‚Äú, ktor√© mo≈æno pou≈æi≈• na riaden√© aj neriaden√© uƒçenie. V tejto met√≥de sa vytvor√≠ preddefinovan√Ω poƒçet bodov a okolo nich sa zhroma≈æƒèuj√∫ d√°ta, aby sa mohli predpoveda≈• v≈°eobecn√© labely pre d√°ta.

### Cviƒçenie - aplikujte K-Neighbors klasifik√°tor

Predch√°dzaj√∫ci klasifik√°tor bol dobr√Ω a dobre fungoval s d√°tami, ale mo≈æno m√¥≈æeme dosiahnu≈• lep≈°iu presnos≈•. Sk√∫ste K-Neighbors klasifik√°tor.

1. Pridajte riadok do poƒæa klasifik√°torov (pridajte ƒçiarku za polo≈æku Line√°rny SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    V√Ωsledok je mierne hor≈°√≠:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Nauƒçte sa o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector Classifier

Support-Vector klasifik√°tory s√∫ s√∫ƒças≈•ou rodiny [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine), ktor√© sa pou≈æ√≠vaj√∫ pre klasifikaƒçn√© a regresn√© √∫lohy. SVM ‚Äûmapuje tr√©ningov√© pr√≠klady do bodov v priestore‚Äú, aby maximalizoval vzdialenos≈• medzi dvoma kateg√≥riami. N√°sledn√© d√°ta sa mapuj√∫ do tohto priestoru, aby sa mohla predpoveda≈• ich kateg√≥ria.

### Cviƒçenie - aplikujte Support Vector Classifier

Sk√∫sme dosiahnu≈• trocha lep≈°iu presnos≈• pomocou Support Vector Classifier.

1. Pridajte ƒçiarku za polo≈æku K-Neighbors a potom pridajte tento riadok:

    ```python
    'SVC': SVC(),
    ```

    V√Ωsledok je celkom dobr√Ω!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Nauƒçte sa o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble Classifiers

Poƒème pokraƒçova≈• a≈æ do konca cesty, aj keƒè bol predch√°dzaj√∫ci test dos≈• dobr√Ω. Sk√∫sme ‚ÄûEnsemble Classifiers‚Äú, konkr√©tne Random Forest a AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

V√Ωsledok je veƒæmi dobr√Ω, najm√§ pre Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Nauƒçte sa o [Ensemble Classifiers](https://scikit-learn.org/stable/modules/ensemble.html)

T√°to met√≥da strojov√©ho uƒçenia "kombinuje predpovede niekoƒæk√Ωch z√°kladn√Ωch odhadcov" pre zlep≈°enie kvality modelu. V na≈°om pr√≠klade sme pou≈æili n√°hodn√© stromy a AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), met√≥da priemerovania, vytv√°ra ‚Äûles‚Äú rozhodovac√≠ch stromov obohaten√Ωch n√°hodnos≈•ou, aby sa predi≈°lo preuƒçeniu. Parameter n_estimators je nastaven√Ω na poƒçet stromov.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) prisp√¥sob√≠ klasifik√°tor d√°tovej sade a potom prisp√¥sob√≠ k√≥pie tohto klasifik√°tora danej sade. Zameriava sa na v√°hy nespr√°vne klasifikovan√Ωch polo≈æiek a upravuje prisp√¥sobenie pre ƒèal≈°√≠ klasifik√°tor, aby to opravil.

---

## üöÄV√Ωzva

Ka≈æd√° z t√Ωchto techn√≠k m√° veƒæk√© mno≈æstvo parametrov, ktor√© m√¥≈æete upravova≈•. Presk√∫majte predvolen√© parametre ka≈æd√©ho z nich a zamyslite sa, ƒço by znamenalo ich upravovanie pre kvalitu modelu.

## [Po predn√°≈°ke kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

## Recenzia a samostatn√© ≈°t√∫dium

T√Ωchto lekci√≠ je veƒæa odborn√Ωch v√Ωrazov, preto si dajte chv√≠ƒæu na pre≈°tudovanie [tohto zoznamu](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) u≈æitoƒçnej terminol√≥gie!

## Zadanie

[Hra s parametrami](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Upozornenie**:
Tento dokument bol prelo≈æen√Ω pomocou AI prekladateƒæskej slu≈æby [Co-op Translator](https://github.com/Azure/co-op-translator). Aj keƒè sa sna≈æ√≠me o presnos≈•, pros√≠m, majte na pam√§ti, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. Origin√°lny dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre d√¥le≈æit√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nezodpoved√°me za ak√©koƒævek nepochopenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->