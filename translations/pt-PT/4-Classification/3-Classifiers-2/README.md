# Classificadores de cozinha 2

Nesta segunda li√ß√£o de classifica√ß√£o, ir√° explorar mais formas de classificar dados num√©ricos. Tamb√©m aprender√° sobre as ramifica√ß√µes de escolher um classificador em vez de outro.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ml/)

### Pr√©-requisito

Assumimos que completou as li√ß√µes anteriores e que tem um conjunto de dados limpo na sua pasta `data` chamado _cleaned_cuisines.csv_ na raiz desta pasta de 4 li√ß√µes.

### Prepara√ß√£o

Carreg√°mos o seu ficheiro _notebook.ipynb_ com o conjunto de dados limpo e dividimo-lo em dataframes X e y, prontos para o processo de constru√ß√£o do modelo.

## Um mapa de classifica√ß√£o

Anteriormente, aprendeu sobre as v√°rias op√ß√µes que tem ao classificar dados utilizando o cheat sheet da Microsoft. O Scikit-learn oferece um cheat sheet semelhante, mas mais granular, que pode ajudar a restringir ainda mais os seus estimadores (outro termo para classificadores):

![ML Map from Scikit-learn](../../../../translated_images/pt-PT/map.e963a6a51349425a.webp)
> Dica: [visite este mapa online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) e clique ao longo do percurso para ler a documenta√ß√£o.

### O plano

Este mapa √© muito √∫til quando tem uma compreens√£o clara dos seus dados, pois pode 'percorrer' os seus caminhos at√© uma decis√£o:

- Temos >50 amostras
- Queremos prever uma categoria
- Temos dados rotulados
- Temos menos de 100K amostras
- ‚ú® Podemos escolher um Linear SVC
- Se isso n√£o funcionar, uma vez que temos dados num√©ricos
    - Podemos tentar um ‚ú® KNeighbors Classifier
      - Se isso n√£o funcionar, tente ‚ú® SVC e ‚ú® Ensemble Classifiers

Este √© um caminho muito √∫til a seguir.

## Exerc√≠cio - dividir os dados

Seguindo este percurso, devemos come√ßar por importar algumas bibliotecas para usar.

1. Importe as bibliotecas necess√°rias:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divida os seus dados de treino e de teste:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Classificador Linear SVC

O Support-Vector clustering (SVC) √© um m√©todo da fam√≠lia de m√°quinas de vetores de suporte (Support-Vector machines) em ML (saiba mais sobre estes abaixo). Neste m√©todo, pode escolher um 'kernel' para decidir como agrupar as etiquetas. O par√¢metro 'C' refere-se √† 'regulariza√ß√£o', que regula a influ√™ncia dos par√¢metros. O kernel pode ser um de [v√°rios](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); aqui definimo-lo como 'linear' para garantir que utilizamos o SVC linear. A probabilidade √© por defeito 'false'; aqui definimo-la como 'true' para recolher estimativas de probabilidade. Definimos o estado aleat√≥rio para '0' para embaralhar os dados e obter probabilidades.

### Exerc√≠cio - aplicar um Linear SVC

Comece por criar um array de classificadores. Ir√° adicionar progressivamente a este array conforme formos testando.

1. Comece com um Linear SVC:

    ```python
    C = 10
    # Criar diferentes classificadores.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Treine o seu modelo usando o Linear SVC e imprima um relat√≥rio:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    O resultado √© bastante bom:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificador K-Neighbors

K-Neighbors faz parte da fam√≠lia "neighbors" de m√©todos ML, que podem ser usados para aprendizagem supervisionada e n√£o supervisionada. Neste m√©todo, um n√∫mero predefinido de pontos √© criado e os dados s√£o agrupados √† volta destes pontos de forma a prever etiquetas generalizadas para os dados.

### Exerc√≠cio - aplicar o classificador K-Neighbors

O classificador anterior foi bom, e funcionou bem com os dados, mas talvez consigamos melhor precis√£o. Experimente um classificador K-Neighbors.

1. Adicione uma linha ao seu array de classificadores (adicione uma v√≠rgula ap√≥s o item Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    O resultado √© um pouco pior:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Saiba mais sobre [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificador Support Vector

Os classificadores Support-Vector fazem parte da fam√≠lia de m√©todos ML [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) que s√£o usados para tarefas de classifica√ß√£o e regress√£o. Os SVMs "mapeiam exemplos de treino para pontos no espa√ßo" para maximizar a dist√¢ncia entre duas categorias. Os dados subsequentes s√£o mapeados neste espa√ßo para que a sua categoria possa ser prevista.

### Exerc√≠cio - aplicar um classificador Support Vector

Vamos tentar obter uma precis√£o um pouco melhor com um classificador Support Vector.

1. Adicione uma v√≠rgula ap√≥s o item K-Neighbors, e depois adicione esta linha:

    ```python
    'SVC': SVC(),
    ```

    O resultado √© bastante bom!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Saiba mais sobre [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificadores Ensemble

Vamos seguir o percurso at√© ao fim, embora o teste anterior tenha sido bastante bom. Vamos experimentar alguns 'Classificadores Ensemble', especificamente Random Forest e AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

O resultado √© muito bom, especialmente para o Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Saiba mais sobre [Classificadores Ensemble](https://scikit-learn.org/stable/modules/ensemble.html)

Este m√©todo de Aprendizagem Autom√°tica "combina as previs√µes de v√°rios estimadores base" para melhorar a qualidade do modelo. No nosso exemplo, usamos √Årvores Aleat√≥rias e AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), um m√©todo de m√©dia, constr√≥i uma 'floresta' de '√°rvores de decis√£o' com aleatoriedade para evitar o sobreajuste. O par√¢metro n_estimators √© definido para o n√∫mero de √°rvores.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajusta um classificador a um conjunto de dados e depois ajusta c√≥pias desse classificador ao mesmo conjunto de dados. Foca-se nos pesos dos itens classificados incorretamente e ajusta o ajuste para o classificador seguinte corrigir.

---

## üöÄDesafio

Cada uma destas t√©cnicas tem um n√∫mero grande de par√¢metros que pode ajustar. Pesquise os par√¢metros por defeito de cada uma e pense no que ajustar estes par√¢metros significaria para a qualidade do modelo.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Estudo aut√≥nomo

H√° muita terminologia nestas li√ß√µes, por isso reserve um minuto para rever [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de termos √∫teis!

## Tarefa

[Jogar com par√¢metros](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, note que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original, na sua l√≠ngua nativa, deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por um tradutor humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes da utiliza√ß√£o desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->