# Cuisine classifiers 2

In dieser zweiten Klassifikationslektion werden Sie weitere M√∂glichkeiten zur Klassifikation numerischer Daten erkunden. Au√üerdem erfahren Sie die Auswirkungen der Wahl eines Klassifikators gegen√ºber einem anderen.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ml/)

### Voraussetzung

Wir gehen davon aus, dass Sie die vorherigen Lektionen abgeschlossen haben und einen bereinigten Datensatz in Ihrem `data`-Ordner mit dem Namen _cleaned_cuisines.csv_ im Stammverzeichnis dieses 4-Lektionen-Ordners haben.

### Vorbereitung

Wir haben Ihre _notebook.ipynb_-Datei mit dem bereinigten Datensatz geladen und in X- und y-Datenrahmen aufgeteilt, bereit f√ºr den Modellierungsprozess.

## Eine Klassifikationskarte

Zuvor haben Sie die verschiedenen Optionen kennengelernt, die Sie bei der Klassifikation von Daten anhand des Cheat Sheets von Microsoft haben. Scikit-learn bietet ein √§hnliches, aber detaillierteres Cheat Sheet, das Ihnen dabei helfen kann, Ihre Sch√§tzer (ein anderer Begriff f√ºr Klassifikatoren) weiter einzugrenzen:

![ML Map from Scikit-learn](../../../../translated_images/de/map.e963a6a51349425a.webp)
> Tipp: [besuchen Sie diese Karte online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) und klicken Sie dem Pfad entlang, um die Dokumentation zu lesen.

### Der Plan

Diese Karte ist sehr hilfreich, sobald Sie ein klares Verst√§ndnis Ihrer Daten haben, da Sie den Pfaden zu einer Entscheidung folgen k√∂nnen:

- Wir haben >50 Stichproben
- Wir wollen eine Kategorie vorhersagen
- Wir haben gelabelte Daten
- Wir haben weniger als 100.000 Stichproben
- ‚ú® Wir k√∂nnen einen Linear SVC w√§hlen
- Falls das nicht funktioniert, da wir numerische Daten haben
    - K√∂nnen wir einen ‚ú® KNeighbors Classifier ausprobieren
      - Wenn das nicht funktioniert, versuchen Sie ‚ú® SVC und ‚ú® Ensemble Classifier

Dies ist eine sehr hilfreiche Vorgehensweise.

## √úbung - Daten aufteilen

Folgen wir diesem Pfad, sollten wir zun√§chst einige Bibliotheken zum Verwenden importieren.

1. Importieren Sie die ben√∂tigten Bibliotheken:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Teilen Sie Ihre Trainings- und Testdaten auf:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_features_df, cuisines_label_df, test_size=0.3)
    ```

## Linear SVC Klassifikator

Support-Vektor-Clustering (SVC) ist ein Teil der Familie der Support-Vektor-Maschinen (lernen Sie unten mehr √ºber diese kennen). Bei dieser Methode k√∂nnen Sie einen ‚ÄûKernel‚Äú ausw√§hlen, um zu entscheiden, wie die Labels gruppiert werden. Der Parameter ‚ÄûC‚Äú bezieht sich auf ‚ÄûRegularisierung‚Äú, also die Regulierung des Einflusses von Parametern. Der Kernel kann einer von [mehreren](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) sein; hier setzen wir ihn auf ‚Äûlinear‚Äú, um linear SVC zu verwenden. Die Wahrscheinlichkeit ist standardm√§√üig ‚Äûfalse‚Äú; hier setzen wir sie auf ‚Äûtrue‚Äú, um Wahrscheinlichkeitsabsch√§tzungen zu erhalten. Wir setzen den Zufallszustand auf ‚Äû0‚Äú, um die Daten zu mischen und Wahrscheinlichkeiten zu ermitteln.

### √úbung - Anwenden eines Linear SVC

Beginnen Sie damit, ein Array von Klassifikatoren zu erstellen. Sie werden dieses Array nach und nach erweitern, w√§hrend wir testen.

1. Beginnen Sie mit einem Linear SVC:

    ```python
    C = 10
    # Erstellen Sie verschiedene Klassifikatoren.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Trainieren Sie Ihr Modell mit dem Linear SVC und geben Sie einen Bericht aus:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Das Ergebnis ist recht gut:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors Klassifikator

K-Neighbors geh√∂rt zur Familie der ‚ÄûNachbarn‚Äú-ML-Methoden, die f√ºr √ºberwachtes und un√ºberwachtes Lernen eingesetzt werden k√∂nnen. Bei dieser Methode wird eine vordefinierte Anzahl an Punkten erstellt, und die Daten werden um diese Punkte gruppiert, sodass verallgemeinerte Labels f√ºr die Daten vorhergesagt werden k√∂nnen.

### √úbung - Anwenden des K-Neighbors Klassifikators

Der vorherige Klassifikator war gut und funktionierte gut mit den Daten, aber vielleicht k√∂nnen wir eine bessere Genauigkeit erreichen. Versuchen Sie einen K-Neighbors Klassifikator.

1. F√ºgen Sie Ihrem Klassifikator-Array eine Linie hinzu (setzen Sie ein Komma nach dem Linear SVC-Element):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Das Ergebnis ist etwas schlechter:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Lernen Sie mehr √ºber [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector Classifier

Support-Vektor-Klassifikatoren sind Teil der Familie der [Support-Vektor-Maschinen](https://wikipedia.org/wiki/Support-vector_machine), die f√ºr Klassifikations- und Regressionsaufgaben eingesetzt werden. SVMs ‚Äûbilden Trainingsbeispiele als Punkte im Raum ab‚Äú, um den Abstand zwischen zwei Kategorien zu maximieren. Nachfolgende Daten werden in diesen Raum abgebildet, sodass ihre Kategorie vorhergesagt werden kann.

### √úbung - Anwenden eines Support Vector Classifier

Versuchen wir eine etwas bessere Genauigkeit mit einem Support Vector Classifier.

1. F√ºgen Sie nach dem K-Neighbors-Element ein Komma ein und dann diese Zeile:

    ```python
    'SVC': SVC(),
    ```

    Das Ergebnis ist ziemlich gut!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Lernen Sie mehr √ºber [Support-Vektoren](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble-Klassifikatoren

Folgen wir dem Pfad bis zum Ende, obwohl der vorherige Test recht gut war. Versuchen wir einige ‚ÄûEnsemble-Klassifikatoren‚Äú, speziell Random Forest und AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Das Ergebnis ist sehr gut, besonders f√ºr Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Lernen Sie mehr √ºber [Ensemble-Klassifikatoren](https://scikit-learn.org/stable/modules/ensemble.html)

Diese Methode des Maschinellen Lernens ‚Äûkombiniert die Vorhersagen mehrerer Basis-Sch√§tzer‚Äú, um die Qualit√§t des Modells zu verbessern. In unserem Beispiel verwendeten wir Random Trees und AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), eine Mittelungsmethode, baut einen ‚ÄûWald‚Äú aus ‚ÄûEntscheidungsb√§umen‚Äú, der mit Zuf√§lligkeit versehen ist, um Overfitting zu vermeiden. Der Parameter n_estimators wird auf die Anzahl der B√§ume gesetzt.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) passt einen Klassifikator an einen Datensatz an und passt dann Kopien dieses Klassifikators an denselben Datensatz an. Es fokussiert sich auf die Gewichte falsch klassifizierter Elemente und passt die Gewichtung f√ºr den n√§chsten Klassifikator an, um Fehler zu korrigieren.

---

## üöÄHerausforderung

Jede dieser Techniken hat eine gro√üe Anzahl von Parametern, die Sie anpassen k√∂nnen. Recherchieren Sie die Standardparameter jedes Verfahrens und denken Sie dar√ºber nach, was die Anpassung dieser Parameter f√ºr die Qualit√§t des Modells bedeuten w√ºrde.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ml/)

## R√ºckblick & Selbststudium

In diesen Lektionen gibt es viele Fachbegriffe, nehmen Sie sich also eine Minute, um [diese Liste](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) mit n√ºtzlichen Begriffen durchzugehen!

## Aufgabe

[Parameter spielen](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe des KI-√úbersetzungsdienstes [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Ursprungssprache ist als ma√ügebliche Quelle zu betrachten. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->